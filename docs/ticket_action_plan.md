---

# **Webtoon Sequence Analysis & Recommendation Agent with PathRAG - ìƒì„¸ ì‹¤í–‰ ê³„íš (v3 - ìµœì¢… í†µí•©ë³¸)**

## **Phase 1: í™˜ê²½ ì„¤ì • ë° ë‹¤ì¤‘ ì—í”¼ì†Œë“œ ë¶„ì„ Agent êµ¬í˜„**

### **WCAI-P01: í”„ë¡œì íŠ¸ í™˜ê²½ ì„¤ì • (PathRAG í¬í•¨)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 60ë¶„)

- **ì„¤ëª…:** PathRAG ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í¬í•¨í•˜ì—¬ ê°œë°œ í™˜ê²½ì„ ì„¤ì •í•˜ê³  ê¸°ë³¸ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **GitHub ì €ì¥ì†Œ ìƒì„± ë° í´ë¡ :**
        - GitHubì—ì„œ `webtoon-analysis-pathrag` ì €ì¥ì†Œ ìƒì„±.
        - ë¡œì»¬ì— í´ë¡ : `git clone <https://github.com/[ì‚¬ìš©ìëª…]/webtoon-analysis-pathrag.git`>
        - í”„ë¡œì íŠ¸ í´ë”ë¡œ ì´ë™: `cd webtoon-analysis-pathrag`
    2. **Git ì´ˆê¸°í™” ë° ê¸°ë³¸ ì„¤ì •:**
        - `.gitignore` íŒŒì¼ ìƒì„± ë° ë‚´ìš© ì¶”ê°€:
            
            ```
            # Virtual environment
            venv/
            .venv/
            
            # Environment variables
            .env
            
            # Python cache
            __pycache__/
            *.pyc
            *.pyo
            
            # OS generated files
            .DS_Store
            Thumbs.db
            
            # PathRAG working directory
            pathrag_working_dir/
            
            # Data exports (optional)
            data/graph_exports/*.html
            data/graph_exports/*.graphml
            
            ```
            
    3. **ê°€ìƒí™˜ê²½ ì„¤ì •:**
        - `python -m venv venv` (ë˜ëŠ” `.venv`)
        - í™œì„±í™” (Windows: `venv\\Scripts\\activate`, macOS/Linux: `source venv/bin/activate`)
    4. **PathRAG ì €ì¥ì†Œ í´ë¡  ë° ì„¤ì¹˜:**
        
        ```bash
        git clone <https://github.com/BUPT-GAMMA/PathRAG.git>
        cd PathRAG
        # (ì„ íƒì ) í•„ìš”ì‹œ íŠ¹ì • ë²„ì „/ë¸Œëœì¹˜ checkout
        pip install -e . # ê°œë°œ ëª¨ë“œë¡œ ì„¤ì¹˜ (ì˜ì¡´ì„± ìë™ ì„¤ì¹˜)
        cd ..
        
        ```
        
    5. **requirements.txt ìƒì„±/ìˆ˜ì •:** í”„ë¡œì íŠ¸ì˜ ë‹¤ë¥¸ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
        
        ```
        # LangChain Core
        langchain==0.1.11 # ë˜ëŠ” ìµœì‹  í˜¸í™˜ ë²„ì „
        langchain-openai==0.0.8 # ë˜ëŠ” ìµœì‹  í˜¸í™˜ ë²„ì „
        langgraph==0.0.26 # ë˜ëŠ” ìµœì‹  í˜¸í™˜ ë²„ì „
        
        # Web UI & Image Handling
        streamlit==1.32.2 # ë˜ëŠ” ìµœì‹  ë²„ì „
        pillow==10.2.0 # ë˜ëŠ” ìµœì‹  ë²„ì „
        
        # Environment & Utilities
        python-dotenv==1.0.1 # ë˜ëŠ” ìµœì‹  ë²„ì „
        
        # Graph Handling & Visualization
        networkx # ê·¸ë˜í”„ ìƒì„±/ê´€ë¦¬ìš© (PathRAG ì„¤ì¹˜ ì‹œ í¬í•¨ë  ìˆ˜ ìˆìŒ)
        pyvis # ê·¸ë˜í”„ ì‹œê°í™”ìš©
        
        # PathRAG (ì„¤ì¹˜ëŠ” ìœ„ì—ì„œ ë³„ë„ ìˆ˜í–‰, ì˜ì¡´ì„± ëª…ì‹œ ëª©ì )
        # í•„ìš”í•œ ê²½ìš° PathRAGì˜ í•µì‹¬ ì˜ì¡´ì„± ì¶”ê°€ í™•ì¸
        # ì˜ˆ: transformers, torch, faiss-cpu ë“± (PathRAGì˜ setup.py ì°¸ê³ )
        
        ```
        
    6. **ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:** `pip install -r requirements.txt` (PathRAG ì„¤ì¹˜ ì‹œ ì´ë¯¸ ì„¤ì¹˜ëœ ê²ƒì€ ê±´ë„ˆ<0xEB><01>ë‹ˆë‹¤.)
    7. **ê¸°ë³¸ í´ë” êµ¬ì¡° ìƒì„±:**
        
        ```bash
        mkdir -p src/agents src/utils src/graph src/analysis data/images data/metadata data/graph_exports config tests docs/images pathrag_working_dir
        touch src/__init__.py src/agents/__init__.py src/utils/__init__.py src/graph/__init__.py src/analysis/__init__.py tests/__init__.py
        
        ```
        
    8. **ì´ˆê¸° ì»¤ë°‹:**
        
        ```bash
        git add .
        git commit -m "Initial project setup with environment, structure, and PathRAG integration"
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:**
    - GitHub ì €ì¥ì†Œê°€ ë¡œì»¬ì— ì—°ê²°ë˜ê³  `.gitignore` íŒŒì¼ì´ ì„¤ì •ë¨.
    - ê°€ìƒí™˜ê²½ í™œì„±í™” ë° PathRAG í¬í•¨ í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ.
    - ì •ì˜ëœ í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ.
    - ì´ˆê¸° ì„¤ì • ìƒíƒœê°€ GitHubì— ì»¤ë°‹ë¨.

### **WCAI-P02: API í‚¤ ì„¤ì • ë° í…ŒìŠ¤íŠ¸** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 15ë¶„)

- **ì„¤ëª…:** LLM/MLLM API ì‚¬ìš©ì„ ìœ„í•œ í‚¤ë¥¼ ì„¤ì •í•˜ê³  ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **.env íŒŒì¼ ìƒì„±:** í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ ìƒì„± (`touch .env`).
    2. **API í‚¤ ì„¤ì •:** `.env` íŒŒì¼ì— ì‚¬ìš©í•˜ëŠ” ëª¨ë¸(OpenAI, Google ë“±)ì˜ API í‚¤ ì¶”ê°€.
        
        ```
        OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx # ì‹¤ì œ í‚¤ ì…ë ¥
        # GOOGLE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx # í•„ìš”ì‹œ
        
        ```
        
        - **ì£¼ì˜:** `.env` íŒŒì¼ì´ `.gitignore`ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    3. **API ì—°ê²° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (`tests/test_api_connection.py`):**
        
        ```python
        import os
        from dotenv import load_dotenv
        from langchain_openai import ChatOpenAI
        # from langchain_google_genai import ChatGoogleGenerativeAI # Gemini ì‚¬ìš© ì‹œ
        
        print("Loading environment variables from .env file...")
        load_dotenv()
        
        print("--- Testing OpenAI API Connection ---")
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key or not api_key.startswith("sk-"): # ê¸°ë³¸ í˜•ì‹ ì²´í¬
            print(f"RESULT: FAIL - OPENAI_API_KEY not found or invalid in .env file (Value: {api_key})")
        else:
            print("OpenAI API Key found.")
            try:
                # ê°„ë‹¨í•œ í˜¸ì¶œë¡œ í…ŒìŠ¤íŠ¸ (ë¹„ìš© ì ê³  ë¹ ë¥¸ ëª¨ë¸ ê¶Œì¥)
                llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0, request_timeout=30)
                response = llm.invoke("Ping: Reply with just 'Pong'.")
                if "pong" in response.content.lower():
                     print("OpenAI API Test Response:", response.content)
                     print("RESULT: SUCCESS - OpenAI API connection successful!")
                else:
                     print(f"RESULT: UNEXPECTED RESPONSE - API connected but response was: {response.content}")
        
            except Exception as e:
                print(f"RESULT: FAIL - Error connecting to OpenAI API: {e}")
        
        # í•„ìš”í•œ ê²½ìš° ë‹¤ë¥¸ API(Google ë“±) í…ŒìŠ¤íŠ¸ ë¡œì§ ì¶”ê°€
        # ...
        
        ```
        
    4. **í…ŒìŠ¤íŠ¸ ì‹¤í–‰:** í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ `python tests/test_api_connection.py` ì‹¤í–‰.
- **ì™„ë£Œ ê¸°ì¤€:**
    - `.env` íŒŒì¼ì— ìœ íš¨í•œ API í‚¤ê°€ ì„¤ì •ë¨.
    - í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œ ì‚¬ìš©í•˜ëŠ” APIì— ëŒ€í•´ "RESULT: SUCCESS" ë©”ì‹œì§€ ì¶œë ¥.

### **WCAI-P03: í”„ë¡œì íŠ¸ ë²”ìœ„ ì •ì˜ ë° êµ¬ì¡° ì„¤ê³„ (ë‹¤ì¤‘ ì—í”¼ì†Œë“œ + PathRAG)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 60ë¶„)

- **ì„¤ëª…:** ìµœì†Œ 3ê°œ ì—°ì† ì—í”¼ì†Œë“œ ë¶„ì„ ë° PathRAGë¥¼ ì´ìš©í•œ ê´€ê³„ ë¶„ì„/ì¶”ì²œ ê¸°ëŠ¥ì„ í¬í•¨í•œ ì „ì²´ í”„ë¡œì íŠ¸ ë²”ìœ„ì™€ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. [**README.md](http://readme.md/) ì‘ì„±/ì—…ë°ì´íŠ¸:** í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `README.md` íŒŒì¼ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸. ì•„ë˜ ë‚´ìš© í¬í•¨.
        
        ```markdown
        # Webtoon Sequence Analysis & Recommendation Agent with PathRAG (PoC)
        
        ## ğŸš€ í”„ë¡œì íŠ¸ ê°œìš”
        
        ì´ í”„ë¡œì íŠ¸ëŠ” ì›¹íˆ° ì½˜í…ì¸ (ì´ë¯¸ì§€+í…ìŠ¤íŠ¸)ë¥¼ ìë™ìœ¼ë¡œ ì´í•´í•˜ê³  ë¶„ì„í•˜ëŠ” AI ì—ì´ì „íŠ¸ì˜ Proof-of-Concept(PoC)ì…ë‹ˆë‹¤. LangGraph ê¸°ë°˜ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œë³„ ì›¹íˆ°ì˜ **ì—°ì†ëœ ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤(ìµœì†Œ 3íšŒì°¨)**ì˜ ë‚´ìš©ì„ ì‹¬ì¸µ ë¶„ì„í•˜ê³ , **PathRAG ê¸°ìˆ ì„ í†µí•©í•˜ì—¬ ì›¹íˆ° ê°„ì˜ ë³µì¡í•œ ê´€ê³„ì„±ì„ ë¶„ì„í•˜ë©° ê°œì¸í™”ëœ ì¶”ì²œ ê¸°ëŠ¥ì„ ì œê³µ**í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
        
        ## ğŸ¯ PoC ë²”ìœ„
        
        * **ì…ë ¥:** ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŠ¹ì • ì›¹íˆ°ì˜ **ì—°ì†ëœ ì—í”¼ì†Œë“œ ì „ì²´ ìŠ¤í¬ë¡¤ ì´ë¯¸ì§€ íŒŒì¼ ì—¬ëŸ¬ ê°œ**.
        * **ì²˜ë¦¬ 1 (WCAI Agent - Sequence Analysis):**
            * ê° ì—í”¼ì†Œë“œ ì´ë¯¸ì§€ì—ì„œ MLLM(GPT-4o ë“±)ì„ ì´ìš©í•´ í…ìŠ¤íŠ¸ ì¶”ì¶œ(OCR) ë° ì‹œê°ì  ë‚´ìš© ë™ì‹œ ë¶„ì„.
            * ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ LLM(GPT-4o-mini ë“±)ìœ¼ë¡œ **ì‹œí€€ìŠ¤ ì „ì²´ ìš”ì•½** ìƒì„± (LangGraph ì›Œí¬í”Œë¡œìš°).
        * **ì²˜ë¦¬ 2 (Graph Construction):**
            * ì—ì´ì „íŠ¸ ë¶„ì„ ê²°ê³¼ ë° ë©”íƒ€ë°ì´í„° ê¸°ë°˜ **íŠ¹ì§• ì¶”ì¶œ** (ì£¼ì œ, íƒœê·¸, ìºë¦­í„° ê´€ê³„ ë³€í™” ë“±).
            * ì›¹íˆ° ì§€ì‹ ê·¸ë˜í”„ ìë™ êµ¬ì¶• (NetworkX): ì›¹íˆ°, ì‘ê°€, ì¥ë¥´, íƒœê·¸, íŠ¹ì§• ë“±ì„ ë…¸ë“œë¡œ, ê´€ê³„ë¥¼ ì—£ì§€ë¡œ í‘œí˜„.
        * **ì²˜ë¦¬ 3 (PathRAG Integration):**
            * ì›¹íˆ° ë©”íƒ€ë°ì´í„° + ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ + ì¶”ì¶œëœ íŠ¹ì§•ì„ ìƒì„¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ PathRAG ì¸ë±ì‹±.
            * PathRAGë¥¼ í™œìš©í•œ ìì—°ì–´ ì¿¼ë¦¬ ê¸°ë°˜ **ê´€ê³„ ë¶„ì„** ë° **ì¶”ì²œ** ìˆ˜í–‰.
        * **ì¶œë ¥:** ê°œë³„ ì—í”¼ì†Œë“œ ë¶„ì„ ê²°ê³¼, ì‹œí€€ìŠ¤ ì „ì²´ ìš”ì•½, PathRAG ì¿¼ë¦¬ ê²°ê³¼(í…ìŠ¤íŠ¸), ê·¸ë˜í”„ ì‹œê°í™”(HTML).
        * **UI:** Streamlit ê¸°ë°˜ ì›¹ ì¸í„°í˜ì´ìŠ¤ (ë‹¤ì¤‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ, ìƒ˜í”Œ ì‹œí€€ìŠ¤ ì„ íƒ, ë¶„ì„ ê²°ê³¼ í‘œì‹œ, PathRAG ì¿¼ë¦¬ ì…ë ¥/ê²°ê³¼ í‘œì‹œ, ê·¸ë˜í”„ ì‹œê°í™” ì—°ë™).
        
        ## âœ¨ ì£¼ìš” ê¸°ëŠ¥ ëª©ë¡
        
        * ì›¹íˆ° ì „ì²´ ìŠ¤í¬ë¡¤ ì´ë¯¸ì§€ ê¸°ë°˜ ìë™ í…ìŠ¤íŠ¸ ì¶”ì¶œ(OCR) ë° ì‹œê° ë¶„ì„.
        * **ì—°ì†ëœ ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤**ì— ëŒ€í•œ í†µí•© ìš”ì•½ ìƒì„±.
        * ì‹œí€€ìŠ¤ ë¶„ì„ ê¸°ë°˜ **ì›¹íˆ° íŠ¹ì§• ìë™ ì¶”ì¶œ** (ì£¼ì œ, íƒœê·¸, ìºë¦­í„° ê´€ê³„ ë“±).
        * ì›¹íˆ° ì§€ì‹ ê·¸ë˜í”„ ìë™ êµ¬ì¶• ë° ì‹œê°í™”.
        * PathRAGë¥¼ ì´ìš©í•œ ë¬¸ë§¥ ê¸°ë°˜ ì›¹íˆ° ì •ë³´ ê²€ìƒ‰ ë° ê´€ê³„ ì¶”ë¡ .
        * **ë‹¤ê°ì  ìœ ì‚¬ ì›¹íˆ° ì¶”ì²œ** (ë‚´ìš©, ìŠ¤íƒ€ì¼, ì¥ë¥´, ê´€ê³„ ë“± ê¸°ë°˜).
        * ì›¹íˆ° íŠ¸ë Œë“œ ë° **ì¸ê¸° íŒ¨í„´ ë¶„ì„** ì§€ì› (PathRAG ì¿¼ë¦¬ í™œìš©).
        * **í¬ë¦¬ì—ì´í„° ì „ëµ ë¶„ì„** ì§€ì› (PathRAG ì¿¼ë¦¬ í™œìš©).
        
        ## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ
        
        * **AI Workflow:** LangChain & LangGraph
        * **Core Models:** OpenAI GPT-4o / GPT-4o-mini (ë˜ëŠ” Gemini Pro Vision/1.5 Pro)
        * **Graph RAG:** **PathRAG (BUPT-GAMMA)**
        * **Graph Handling:** **NetworkX**
        * **Web Interface:** Streamlit
        * **Development:** Python
        * **Graph Visualization:** PyVis
        
        ---
        *(READMEì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„: ì„¤ì¹˜ ë°©ë²•, ì‚¬ìš© ë°©ë²•, í”„ë¡œì íŠ¸ êµ¬ì¡° ë“±ì€ ì´í›„ ë‹¨ê³„ì—ì„œ êµ¬ì²´í™”ë©ë‹ˆë‹¤.)*
        
        ```
        
    2. **ì½”ë“œ êµ¬ì¡° ì„¤ê³„ ë¬¸ì„œ ì‘ì„±/ì—…ë°ì´íŠ¸ (`docs/design.md`):**
    webtoon-analysis-pathrag/
    â”‚
    â”œâ”€â”€ [app.py](http://app.py/) # Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ íŒŒì¼
    â”‚
    â”œâ”€â”€ requirements.txt # Python ì˜ì¡´ì„± ëª©ë¡
    â”œâ”€â”€ .env # API í‚¤ ë“± í™˜ê²½ ë³€ìˆ˜ (Git ë¯¸í¬í•¨)
    â”œâ”€â”€ .gitignore # Git ì¶”ì  ì œì™¸ ëª©ë¡
    â”‚
    â”œâ”€â”€ src/ # ì†ŒìŠ¤ ì½”ë“œ ë£¨íŠ¸
    â”‚ â”œâ”€â”€ **init**.py
    â”‚ â”‚
    â”‚ â”œâ”€â”€ agents/ # LangGraph ê¸°ë°˜ ì›¹íˆ° ë¶„ì„ ì—ì´ì „íŠ¸
    â”‚ â”‚ â”œâ”€â”€ **init**.py
    â”‚ â”‚ â””â”€â”€ webtoon_agent.py # SequenceAgentState, ë…¸ë“œ í•¨ìˆ˜, ê·¸ë˜í”„ ì •ì˜
    â”‚ â”‚
    â”‚ â”œâ”€â”€ analysis/ # ì›¹íˆ° íŠ¹ì§• ì¶”ì¶œ ë° PathRAG ë¶„ì„ ê´€ë ¨
    â”‚ â”‚ â”œâ”€â”€ **init**.py
    â”‚ â”‚ â”œâ”€â”€ feature_extractor.py # ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ ë¡œì§
    â”‚ â”‚ â””â”€â”€ pathrag_analyzer.py # PathRAG ì¿¼ë¦¬ í•¨ìˆ˜ êµ¬í˜„ (ì¶”ì²œ, íŒ¨í„´ ë“±)
    â”‚ â”‚
    â”‚ â”œâ”€â”€ graph/ # ê·¸ë˜í”„ ë°ì´í„° ë° PathRAG ì—°ë™
    â”‚ â”‚ â”œâ”€â”€ **init**.py
    â”‚ â”‚ â”œâ”€â”€ graph_model.py # NetworkX ê¸°ë°˜ ê·¸ë˜í”„ ëª¨ë¸ ì •ì˜
    â”‚ â”‚ â”œâ”€â”€ graph_manager.py # ê·¸ë˜í”„ ìƒì„±, ê´€ë¦¬, ì‹œê°í™” ë¡œì§
    â”‚ â”‚ â””â”€â”€ pathrag_integration.py# PathRAG ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—°ë™ ë° ì¸ë±ì‹±/ì¿¼ë¦¬
    â”‚ â”‚
    â”‚ â””â”€â”€ utils/ # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    â”‚ â”œâ”€â”€ **init**.py
    â”‚ â””â”€â”€ data_loader.py # ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ ë°ì´í„° ë¡œë”© ìœ í‹¸ë¦¬í‹°
    â”‚
    â”œâ”€â”€ data/ # ë°ì´í„° íŒŒì¼
    â”‚ â”œâ”€â”€ images/ # ìƒ˜í”Œ ì›¹íˆ° ì´ë¯¸ì§€ (ì—í”¼ì†Œë“œë³„ ê¸´ ìŠ¤í¬ë¡¤)
    â”‚ â”œâ”€â”€ metadata/ # ì›¹íˆ°/ì—í”¼ì†Œë“œ ë©”íƒ€ë°ì´í„° (JSON)
    â”‚ â”‚ â”œâ”€â”€ webtoons.json
    â”‚ â”‚ â””â”€â”€ episodes.json (ì„ íƒì )
    â”‚ â””â”€â”€ graph_exports/ # ìƒì„±ëœ ê·¸ë˜í”„ íŒŒì¼(GraphML), ì‹œê°í™”(HTML)
    â”‚
    â”œâ”€â”€ config/ # ì„¤ì • íŒŒì¼ (í•„ìš”ì‹œ, ì˜ˆ: LLM ëª¨ë¸ëª…, PathRAG íŒŒë¼ë¯¸í„°)
    â”‚
    â”œâ”€â”€ tests/ # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    â”‚ â”œâ”€â”€ **init**.py
    â”‚ â”œâ”€â”€ test_api_connection.py
    â”‚ â”œâ”€â”€ test_data_loader.py
    â”‚ â”œâ”€â”€ test_agent_workflow.py # ì‹œí€€ìŠ¤ ë¶„ì„ Agent í…ŒìŠ¤íŠ¸
    â”‚ â”œâ”€â”€ test_feature_extractor.py
    â”‚ â”œâ”€â”€ test_graph_manager.py
    â”‚ â””â”€â”€ test_pathrag_integration.py # PathRAG ì¸ë±ì‹± ë° ê¸°ë³¸ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
    â”‚
    â”œâ”€â”€ scripts/ # ë°ì´í„° ì²˜ë¦¬, ëª¨ë¸ ë¹Œë“œ ë“± ë…ë¦½ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
    â”‚ â”œâ”€â”€ build_graph_pipeline.py # ì „ì²´ ê·¸ë˜í”„ êµ¬ì¶• ìë™í™” ìŠ¤í¬ë¦½íŠ¸
    â”‚ â””â”€â”€ build_pathrag_index.py # PathRAG ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸
    â”‚
    â”œâ”€â”€ docs/ # ë¬¸ì„œ ë° ì„¤ê³„ íŒŒì¼
    â”‚ â”œâ”€â”€ [design.md](http://design.md/) # ë³¸ ì„¤ê³„ ë¬¸ì„œ
    â”‚ â”œâ”€â”€ graph_schema.md # ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ ìƒì„¸ ì •ì˜ (ì„ íƒì )
    â”‚ â””â”€â”€ images/ # READMEìš© ì´ë¯¸ì§€, ë°ëª¨ ìŠ¤í¬ë¦°ìƒ· ë“±
    â”‚
    â””â”€â”€ pathrag_working_dir/ # PathRAG ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‘ì—… ë””ë ‰í† ë¦¬ (Git ë¯¸í¬í•¨)
        
        ```markdown
        # ì½”ë“œ êµ¬ì¡° ë° ë°ì´í„° íë¦„ ì„¤ê³„ (v3: Sequence + PathRAG)
        
        ## 1. ì½”ë“œ êµ¬ì¡° (Code Structure)
        
        ```
        
        ```
        
        ## 2. ë°ì´í„° íë¦„ (Data Flow)
        
        1.  **ì…ë ¥:** ì‚¬ìš©ìê°€ Streamlit UI í†µí•´ ì›¹íˆ°ì˜ ì—°ì†ëœ ì—í”¼ì†Œë“œ **ì „ì²´ ìŠ¤í¬ë¡¤ ì´ë¯¸ì§€ ì—¬ëŸ¬ ê°œ** ì—…ë¡œë“œ (`app.py`).
        2.  **ì‹œí€€ìŠ¤ ë¶„ì„ (WCAI Agent):** `src.agents.webtoon_agent`ì˜ LangGraph ì—ì´ì „íŠ¸ê°€ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì…ë ¥ë°›ìŒ.
            * `extract_text_and_analyze_node`: ê° ì´ë¯¸ì§€ë³„ OCR + ì‹œê° ë¶„ì„ ìˆ˜í–‰ (MLLM í˜¸ì¶œ).
            * `summarize_sequence_node`: ëª¨ë“  ì—í”¼ì†Œë“œì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì‹œí€€ìŠ¤ ì „ì²´ ìš”ì•½ ìƒì„± (LLM í˜¸ì¶œ).
            * ê²°ê³¼: ì—í”¼ì†Œë“œë³„ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, ì‹œí€€ìŠ¤ ìš”ì•½ ë“±.
        3.  **(UIí‘œì‹œ)** ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ê°€ Streamlit UIì— í‘œì‹œë¨ (`app.py`).
        4.  **(ë°±ê·¸ë¼ìš´ë“œ/ë°°ì¹˜) íŠ¹ì§• ì¶”ì¶œ:** `src.analysis.feature_extractor`ê°€ ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ + ë©”íƒ€ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¡°í™”ëœ íŠ¹ì§•(íƒœê·¸, ì£¼ì œ, ê´€ê³„ ë³€í™” ë“±) ì¶”ì¶œ (LLM í™œìš©).
        5.  **(ë°±ê·¸ë¼ìš´ë“œ/ë°°ì¹˜) ê·¸ë˜í”„ êµ¬ì¶•:** `src.graph.graph_manager`ê°€ ë©”íƒ€ë°ì´í„°ì™€ ì¶”ì¶œëœ íŠ¹ì§• ì‚¬ìš©í•˜ì—¬ NetworkX ì§€ì‹ ê·¸ë˜í”„ ìƒì„±/ì—…ë°ì´íŠ¸ (`data/graph_exports` ì €ì¥).
            * ê´€ê³„(ì—£ì§€)ëŠ” ê³µí†µ íŠ¹ì§• ë˜ëŠ” LLM/ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ **ìë™ ìƒì„±**.
        6.  **(ë°±ê·¸ë¼ìš´ë“œ/ë°°ì¹˜) PathRAG ì¸ë±ì‹±:** `src.graph.pathrag_integration`ì´ ì›¹íˆ° ë©”íƒ€ë°ì´í„° + ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ + ì¶”ì¶œëœ íŠ¹ì§•ì„ **ìƒì„¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜**í•˜ì—¬ PathRAGì— ì¸ë±ì‹± (`pathrag_working_dir`).
        7.  **PathRAG ì¿¼ë¦¬:** ì‚¬ìš©ìê°€ Streamlit UI í†µí•´ ìì—°ì–´ ì¿¼ë¦¬ ì…ë ¥ (`app.py`).
        8.  **ì¿¼ë¦¬ ì²˜ë¦¬:** `src.analysis.pathrag_analyzer`ê°€ ì¿¼ë¦¬ ìœ í˜•ì— ë§ì¶° `src.graph.pathrag_integration`ì˜ PathRAG ì¿¼ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ.
        9.  **PathRAG ì‘ë‹µ:** PathRAGê°€ ì¸ë±ì‹±ëœ ì •ë³´ì™€ ë‚´ë¶€ ê·¸ë˜í”„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ìµœì¢… ë‹µë³€ í…ìŠ¤íŠ¸ ìƒì„±.
        10. **(UIí‘œì‹œ)** PathRAG ë‹µë³€ì´ Streamlit UIì— í‘œì‹œë¨ (`app.py`).
        11. **(ì„ íƒì  UIí‘œì‹œ)** ê·¸ë˜í”„ ì‹œê°í™” ê²°ê³¼ í‘œì‹œ (`app.py`).
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:**
    - í™•ì¥ëœ ë²”ìœ„ì™€ êµ¬ì¡°ê°€ ë°˜ì˜ëœ README ì´ˆì•ˆ ì™„ë£Œ.
    - ìƒì„¸í™”ëœ ì½”ë“œ êµ¬ì¡° ë° ë°ì´í„° íë¦„ ì„¤ê³„ ë¬¸ì„œ ì´ˆì•ˆ ì™„ë£Œ.

### **WCAI-P04: ìƒ˜í”Œ ì›¹íˆ° ë°ì´í„° í™•ë³´ (ë‹¤ì¤‘ ì—í”¼ì†Œë“œ + ë©”íƒ€ë°ì´í„° ê°•í™”)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 120ë¶„+)

- **ì„¤ëª…:** ë¶„ì„í•  **ìµœì†Œ 10ê°œ ì›¹íˆ°**ì— ëŒ€í•´, ê° ì›¹íˆ°ë‹¹ **ìµœì†Œ 3ê°œ ì—°ì† íšŒì°¨ì˜ ì—í”¼ì†Œë“œ ì „ì²´ ìŠ¤í¬ë¡¤ ì´ë¯¸ì§€**ì™€ ìƒì„¸ ë©”íƒ€ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **10~15ê°œ ì›¹íˆ° ì„ ì •:** ë‹¤ì–‘í•œ ì¥ë¥´/ìŠ¤íƒ€ì¼/í”Œë«í¼ ê³ ë ¤. (ì €ì‘ê¶Œ ìœ ì˜, í•„ìš”ì‹œ CC ë¼ì´ì„ ìŠ¤ ì‘í’ˆ í™œìš©)
    2. **ì—°ì† ì—í”¼ì†Œë“œ ì„ ì •:** ê° ì›¹íˆ°ë³„ë¡œ ë‚´ìš© íë¦„ìƒ ì˜ë¯¸ ìˆëŠ” **ìµœì†Œ 3ê°œ ì—°ì† ì—í”¼ì†Œë“œ** ì„ ì • (ì˜ˆ: ì‹œì¦Œ ì´ˆë°˜ë¶€, íŠ¹ì • ì‚¬ê±´ êµ¬ê°„).
    3. **ì „ì²´ ìŠ¤í¬ë¡¤ ì´ë¯¸ì§€ í™•ë³´:** ì„ ì •ëœ ê° ì—í”¼ì†Œë“œì˜ **ì „ì²´ ìŠ¤í¬ë¡¤**ì„ **í•˜ë‚˜ì˜ ê¸´ ì´ë¯¸ì§€ íŒŒì¼(PNG ë˜ëŠ” JPG)**ë¡œ **ìˆ˜ë™ ìº¡ì²˜/ì €ì¥**. íŒŒì¼ëª… ê·œì¹™ ì •ì˜ (ì˜ˆ: `w001_ep1_full.png`). -> `data/images/`ì— ì €ì¥. (ìë™ ë‹¤ìš´ë¡œë“œ ì ˆëŒ€ ê¸ˆì§€, ì €ì‘ê¶Œ ë° ì•½ê´€ ì¤€ìˆ˜)
    4. **ìƒì„¸ ì›¹íˆ° ë©”íƒ€ë°ì´í„° íŒŒì¼ ì‘ì„± (`data/metadata/webtoons.json`):** ê° ì›¹íˆ°ë³„ ìƒì„¸ ì •ë³´ í¬í•¨.
        
        ```json
        [
          {
            "webtoon_id": "w001",
            "title": "ë‚˜ í˜¼ìë§Œ ë ˆë²¨ì—…", // ì˜ˆì‹œ
            "genre": ["íŒíƒ€ì§€", "ì•¡ì…˜", "í—Œí„°ë¬¼"],
            "tags": ["ë¨¼ì¹˜í‚¨", "ì„±ì¥í˜• ì£¼ì¸ê³µ", "ê²Œì„ ì‹œìŠ¤í…œ", "í˜„ëŒ€ íŒíƒ€ì§€"],
            "art_style": "ì‹¤ì‚¬ì²´",
            "update_frequency": "ì™„ê²°", // ì˜ˆ: ì£¼1íšŒ, ì™„ê²°
            "platform": "ì¹´ì¹´ì˜¤ì›¹íˆ°", // ì˜ˆ: ë„¤ì´ë²„ì›¹íˆ°, ì¹´ì¹´ì˜¤ì›¹íˆ°
            "creator": "ì¶”ê³µ (ì›ì‘), ì¥ì„±ë½ (ê·¸ë¦¼)",
            "popularity_score": 9.8, // ì˜ˆ: 10ì  ë§Œì 
            "is_romance": false,
            "description": "Eê¸‰ í—Œí„° ì„±ì§„ìš°, ì£½ìŒì˜ ìœ„ê¸°ì—ì„œ ì‹œìŠ¤í…œì„ í†µí•´ ë ˆë²¨ì—… ëŠ¥ë ¥ì„ ê°ì„±í•˜ë‹¤...", // ê°„ë‹¨í•œ ì†Œê°œê¸€
            "analysis_episode_sequence": ["w001_ep1", "w001_ep2", "w001_ep3"] // ë¶„ì„ ëŒ€ìƒ ì‹œí€€ìŠ¤ ID ë¦¬ìŠ¤íŠ¸
          },
          {
            "webtoon_id": "w002",
            "title": "ìœ ë¯¸ì˜ ì„¸í¬ë“¤", // ì˜ˆì‹œ
            "genre": ["ë¡œë§¨ìŠ¤", "ì¼ìƒ", "ë“œë¼ë§ˆ", "ì½”ë¯¸ë””"],
            "tags": ["ì„¸í¬", "ì—°ì• ", "ì„±ì¥", "ì§ì¥ì¸"],
            "art_style": "ìºì£¼ì–¼",
            "update_frequency": "ì™„ê²°",
            "platform": "ë„¤ì´ë²„ì›¹íˆ°",
            "creator": "ì´ë™ê±´",
            "popularity_score": 9.5,
            "is_romance": true,
            "description": "30ëŒ€ í‰ë²”í•œ ì§ì¥ì¸ ìœ ë¯¸ì˜ ì—°ì• ì™€ ì¼ìƒì„ ë¨¸ë¦¿ì† ì„¸í¬ë“¤ì˜ ì‹œê°ìœ¼ë¡œ ê·¸ë¦° ì´ì•¼ê¸°.",
            "analysis_episode_sequence": ["w002_ep100", "w002_ep101", "w002_ep102"] // íŠ¹ì • êµ¬ê°„ ì‹œí€€ìŠ¤
          }
          // ... ìµœì†Œ 8~18ê°œ ì›¹íˆ° ì •ë³´ ì¶”ê°€ ...
        ]
        
        ```
        
    5. **(ì„ íƒì ) ì—í”¼ì†Œë“œ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì‘ì„± (`data/metadata/episodes.json`):** ì—í”¼ì†Œë“œ ID, ì›¹íˆ° ID, ì œëª©, ì´ë¯¸ì§€ íŒŒì¼ëª… ë“± ê´€ë¦¬.
        
        ```json
        [
          {"episode_id": "w001_ep1", "webtoon_id": "w001", "title": "1í™” í”„ë¡¤ë¡œê·¸", "image_file": "w001_ep1_full.png"},
          {"episode_id": "w001_ep2", "webtoon_id": "w001", "title": "2í™” ìƒˆë¡œìš´ ì‹œì‘", "image_file": "w001_ep2_full.png"},
          {"episode_id": "w001_ep3", "webtoon_id": "w001", "title": "3í™” ë˜ì „ ì…ì¥", "image_file": "w001_ep3_full.png"},
          // ... ë‹¤ë¥¸ ì—í”¼ì†Œë“œ ì •ë³´ ...
        ]
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:**
    - ìµœì†Œ 10ê°œ ì›¹íˆ°ì˜ ì—°ì† 3íšŒì°¨ ì—í”¼ì†Œë“œ ì „ì²´ ìŠ¤í¬ë¡¤ ì´ë¯¸ì§€ ì¤€ë¹„ ì™„ë£Œ (`data/images/`).
    - ìƒì„¸ ì›¹íˆ° ë©”íƒ€ë°ì´í„° (`webtoons.json`) ì¤€ë¹„ ì™„ë£Œ.
    - (ì„ íƒì ) ì—í”¼ì†Œë“œ ë©”íƒ€ë°ì´í„° (`episodes.json`) ì¤€ë¹„ ì™„ë£Œ.

### **WCAI-P05: ë°ì´í„° ë¡œë”© í•¨ìˆ˜ êµ¬í˜„ (ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 45ë¶„)

- **ì„¤ëª…:** ì›¹íˆ° IDì™€ ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ë‹¹ ì—°ì† ì—í”¼ì†Œë“œë“¤ì˜ ì „ì²´ ìŠ¤í¬ë¡¤ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì™€ ê´€ë ¨ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ìœ í‹¸ë¦¬í‹°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **`WebtoonDataLoader` í´ë˜ìŠ¤ êµ¬í˜„/ìˆ˜ì • (`src/utils/data_loader.py`):**
        
        ```python
        import os
        import json
        from PIL import Image
        from typing import Dict, List, Optional, Tuple
        
        class WebtoonDataLoader:
            def __init__(self, data_dir: str = "data"):
                self.data_dir = data_dir
                self.images_dir = os.path.join(data_dir, "images")
                self.metadata_dir = os.path.join(data_dir, "metadata")
                self.webtoons_meta_path = os.path.join(self.metadata_dir, "webtoons.json")
                self.episodes_meta_path = os.path.join(self.metadata_dir, "episodes.json")
                self.webtoon_metadata = self._load_json(self.webtoons_meta_path) or []
                self.episode_metadata = self._load_json(self.episodes_meta_path) or []
                # ì—í”¼ì†Œë“œ IDë¡œ ë©”íƒ€ë°ì´í„° ë¹ ë¥´ê²Œ ì°¾ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬ (ì„ íƒì  ìµœì í™”)
                self.episode_map = {ep['episode_id']: ep for ep in self.episode_metadata}
        
            def _load_json(self, file_path: str) -> Optional[List[Dict]]:
                """JSON íŒŒì¼ ë¡œë“œ ìœ í‹¸ë¦¬í‹°"""
                if os.path.exists(file_path):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            return json.load(f)
                    except json.JSONDecodeError:
                        print(f"Warning: Could not decode JSON from {file_path}")
                else:
                    print(f"Warning: Metadata file not found at {file_path}")
                return None
        
            def get_all_webtoon_ids(self) -> List[str]:
                """ë¶„ì„ ê°€ëŠ¥í•œ ì›¹íˆ° ID ëª©ë¡ ë°˜í™˜"""
                return [wt['webtoon_id'] for wt in self.webtoon_metadata]
        
            def get_webtoon_metadata(self, webtoon_id: str) -> Optional[Dict]:
                """íŠ¹ì • ì›¹íˆ°ì˜ ë©”íƒ€ë°ì´í„° ë°˜í™˜"""
                for wt in self.webtoon_metadata:
                    if wt['webtoon_id'] == webtoon_id:
                        return wt
                return None
        
            def get_episode_sequence_info(self, webtoon_id: str) -> Optional[Tuple[List[str], List[str]]]:
                """ì›¹íˆ° ë©”íƒ€ë°ì´í„°ì—ì„œ ë¶„ì„ ëŒ€ìƒ ì—í”¼ì†Œë“œ ID ë° ì œëª© ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
                webtoon_meta = self.get_webtoon_metadata(webtoon_id)
                if webtoon_meta:
                    episode_ids = webtoon_meta.get("analysis_episode_sequence", [])
                    episode_titles = []
                    for ep_id in episode_ids:
                        ep_meta = self.episode_map.get(ep_id)
                        episode_titles.append(ep_meta.get("title", "Unknown Title") if ep_meta else "Unknown Title")
                    return episode_ids, episode_titles
                return None
        
            def load_episode_sequence_images(self, webtoon_id: str, episode_ids: List[str]) -> List[Image.Image]:
                """ì£¼ì–´ì§„ ì—í”¼ì†Œë“œ ID ëª©ë¡ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
                images = []
                for ep_id in episode_ids:
                    ep_meta = self.episode_map.get(ep_id)
                    if ep_meta and 'image_file' in ep_meta:
                        img_path = os.path.join(self.images_dir, ep_meta['image_file'])
                        if os.path.exists(img_path):
                            try:
                                img = Image.open(img_path)
                                # RGBA -> RGB ë³€í™˜ (ì¼ë¶€ ëª¨ë¸ í˜¸í™˜ì„±)
                                if img.mode == 'RGBA':
                                    img = img.convert('RGB')
                                images.append(img)
                                print(f"Loaded image: {img_path}")
                            except Exception as e:
                                print(f"Warning: Failed to load image {img_path}. Error: {e}")
                        else:
                            print(f"Warning: Image file not found: {img_path}")
                    else:
                        print(f"Warning: Metadata or image file not defined for episode {ep_id}")
                return images
        
        ```
        
    2. **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±/ìˆ˜ì • (`tests/test_data_loader.py`):**
        
        ```python
        import sys, os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from src.utils.data_loader import WebtoonDataLoader
        
        print("--- DataLoader Test ---")
        loader = WebtoonDataLoader()
        
        webtoon_ids = loader.get_all_webtoon_ids()
        print(f"Available Webtoon IDs: {webtoon_ids}")
        
        if webtoon_ids:
            test_webtoon_id = webtoon_ids[0]
            print(f"\\nTesting with Webtoon ID: {test_webtoon_id}")
        
            webtoon_meta = loader.get_webtoon_metadata(test_webtoon_id)
            print(f"Webtoon Metadata: {webtoon_meta}")
        
            sequence_info = loader.get_episode_sequence_info(test_webtoon_id)
            if sequence_info:
                episode_ids, episode_titles = sequence_info
                print(f"Episode Sequence IDs: {episode_ids}")
                print(f"Episode Sequence Titles: {episode_titles}")
        
                images = loader.load_episode_sequence_images(test_webtoon_id, episode_ids)
                print(f"Loaded {len(images)} images for the sequence.")
                if images:
                    print(f"First image size: {images[0].size}, mode: {images[0].mode}")
                print("RESULT: SUCCESS - Data loading functions seem operational.")
            else:
                print("RESULT: FAIL - Could not retrieve episode sequence info.")
        else:
            print("RESULT: FAIL - No webtoons found in metadata.")
        
        ```
        
    3. **í…ŒìŠ¤íŠ¸ ì‹¤í–‰:** í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ `python tests/test_data_loader.py` ì‹¤í–‰.
- **ì™„ë£Œ ê¸°ì¤€:**
    - ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ì˜ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ë° ê´€ë ¨ ì •ë³´ ë¡œë”© í•¨ìˆ˜ êµ¬í˜„ ì™„ë£Œ.
    - í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì •ìƒ ë™ì‘ í™•ì¸.

### **WCAI-P06: LangGraph ìƒíƒœ ì •ì˜ (ë‹¤ì¤‘ ì—í”¼ì†Œë“œ)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 30ë¶„)

- **ì„¤ëª…:** ì—¬ëŸ¬ ê°œì˜ ì—°ì† ì—í”¼ì†Œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ LangGraph ìƒíƒœ(State)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **`WebtoonSequenceAgentState` ì •ì˜ (`src/agents/webtoon_agent.py`):**
        
        ```python
        from typing import TypedDict, List, Optional, Dict, Any
        from PIL import Image
        
        class WebtoonSequenceAgentState(TypedDict):
            """
            ì›¹íˆ° ì‹œí€€ìŠ¤ ë¶„ì„ ì—ì´ì „íŠ¸ì˜ ìƒíƒœ ì •ì˜ (v3)
            ê° í•„ë“œëŠ” ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì±„ì›Œì§€ê±°ë‚˜ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.
            """
            # === ì…ë ¥ ë°ì´í„° ===
            webtoon_id: str                  # ë¶„ì„ ëŒ€ìƒ ì›¹íˆ°ì˜ ê³ ìœ  ID
            episode_ids: List[str]           # ë¶„ì„í•  ì—í”¼ì†Œë“œ ID ëª©ë¡ (ìˆœì„œ ì¤‘ìš”)
            episode_titles: List[str]        # ì—í”¼ì†Œë“œ ì œëª© ëª©ë¡ (ì…ë ¥ IDsì™€ ìˆœì„œ ì¼ì¹˜)
            images: List[Image.Image]        # ì—í”¼ì†Œë“œë³„ ì „ì²´ ìŠ¤í¬ë¡¤ ì´ë¯¸ì§€ ê°ì²´ ë¦¬ìŠ¤íŠ¸
        
            # === ì¤‘ê°„/ìµœì¢… ì²˜ë¦¬ ê²°ê³¼ ===
            # ì—í”¼ì†Œë“œë³„ ë¶„ì„ ê²°ê³¼
            per_episode_extracted_text: List[str]  # ê° ì—í”¼ì†Œë“œ ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            per_episode_visual_analysis: List[str] # ê° ì—í”¼ì†Œë“œ ì´ë¯¸ì§€ì˜ ì‹œê°ì  ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
            # ì‹œí€€ìŠ¤ ì „ì²´ ì¢…í•© ê²°ê³¼
            sequence_combined_text: str        # ëª¨ë“  ì—í”¼ì†Œë“œì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ ê²°í•©í•œ ë¬¸ìì—´
            sequence_combined_analysis: str    # ëª¨ë“  ì—í”¼ì†Œë“œì˜ ì‹œê°ì  ë¶„ì„ ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ê²°í•©í•œ ë¬¸ìì—´
            sequence_summary: str              # ì‹œí€€ìŠ¤ ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•œ ìµœì¢… ê²°ê³¼ ë¬¸ìì—´
        
            # (ì„ íƒì ) ì¶”ê°€ ë¶„ì„ ê²°ê³¼
            extracted_features: Optional[Dict[str, Any]] # G02ì—ì„œ ì¶”ì¶œëœ íŠ¹ì§• (íƒœê·¸, ì£¼ì œ ë“±)
        
            # === ì˜¤ë¥˜ ì²˜ë¦¬ ===
            error: Optional[str]             # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ ë©”ì‹œì§€
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:** ë‹¤ì¤‘ ì—í”¼ì†Œë“œ ì²˜ë¦¬ë¥¼ ìœ„í•œ `WebtoonSequenceAgentState` ìµœì¢… ì •ì˜ ì™„ë£Œ. ê° í•„ë“œ ì—­í•  ì£¼ì„ ëª…ì‹œ.

### **WCAI-P07: OCR ë° ì´ë¯¸ì§€ ë¶„ì„ ë…¸ë“œ (ë‹¤ì¤‘ ì´ë¯¸ì§€ ì²˜ë¦¬)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 120ë¶„)

- **ì„¤ëª…:** ì…ë ¥ëœ ì—¬ëŸ¬ ê°œì˜ ê¸´ ì—í”¼ì†Œë“œ ì´ë¯¸ì§€ ê°ê°ì— ëŒ€í•´ MLLMìœ¼ë¡œ OCR ë° ì‹œê°ì  ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ìƒíƒœì— ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥í•˜ëŠ” ë…¸ë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **í•„ìš” ëª¨ë“ˆ import ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¤€ë¹„ (`src/agents/webtoon_agent.py`):**
        
        ```python
        import base64
        import io
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import HumanMessage
        from PIL import Image
        import re
        from typing import Dict, List, Tuple, Optional
        
        # ì´ë¯¸ì§€ ì¸ì½”ë”© ìœ í‹¸ë¦¬í‹°
        def encode_image(image: Image.Image, format="JPEG") -> str:
            buffer = io.BytesIO()
            try:
                image.save(buffer, format=format)
                return base64.b64encode(buffer.getvalue()).decode('utf-8')
            except Exception as e:
                print(f"Error encoding image: {e}")
                return ""
        
        # ì‘ë‹µ íŒŒì‹± ìœ í‹¸ë¦¬í‹° (ê°œì„  í•„ìš”)
        def parse_mllm_response(response_content: str) -> Tuple[str, str]:
            """MLLM ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ì™€ ë¶„ì„ ë¶€ë¶„ì„ ë¶„ë¦¬ (ê°œì„ ëœ ë²„ì „)"""
            # ë§ˆì»¤ ê¸°ë°˜ íŒŒì‹±ì„ ë” ëª…í™•í•˜ê²Œ ì‹œë„
            text_marker = "ì¶”ì¶œëœ í…ìŠ¤íŠ¸:"
            analysis_marker = "ì‹œê°ì  ë¶„ì„:"
        
            text_start = response_content.find(text_marker)
            analysis_start = response_content.find(analysis_marker)
        
            extracted_text = "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
            visual_analysis = "ì‹œê°ì  ë¶„ì„ ì‹¤íŒ¨"
        
            if text_start != -1:
                text_content_start = text_start + len(text_marker)
                if analysis_start != -1 and analysis_start > text_start:
                    extracted_text = response_content[text_content_start:analysis_start].strip()
                else: # ì‹œê° ë¶„ì„ ë§ˆì»¤ê°€ ì—†ê±°ë‚˜ í…ìŠ¤íŠ¸ ë’¤ì— ì—†ìœ¼ë©´ ëê¹Œì§€
                    extracted_text = response_content[text_content_start:].strip()
        
            if analysis_start != -1:
                analysis_content_start = analysis_start + len(analysis_marker)
                # í…ìŠ¤íŠ¸ ë¶„ì„ ë§ˆì»¤ê°€ ë’¤ì— ì˜¤ëŠ”ì§€ ì²´í¬ (ìˆœì„œ ë³´ì¥ ì•ˆë  ì‹œ)
                # if text_start != -1 and text_start > analysis_start:
                #     visual_analysis = response_content[analysis_content_start:text_start].strip()
                # else:
                visual_analysis = response_content[analysis_content_start:].strip()
        
            # ê°„ë‹¨í•œ í›„ì²˜ë¦¬ (ë¹ˆ ì¤„ ì œê±° ë“±)
            extracted_text = "\\n".join([line for line in extracted_text.splitlines() if line.strip()])
            visual_analysis = "\\n".join([line for line in visual_analysis.splitlines() if line.strip()])
        
            return extracted_text, visual_analysis
        
        ```
        
    2. **`extract_text_and_analyze_node` í•¨ìˆ˜ êµ¬í˜„ (`src/agents/webtoon_agent.py`):**
        
        ```python
        # ... (imports, WebtoonSequenceAgentState) ...
        
        def extract_text_and_analyze_node(state: WebtoonSequenceAgentState) -> Dict:
            """(Node) ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì—ì„œ OCR ë° ì‹œê°ì  ë¶„ì„ ë™ì‹œ ìˆ˜í–‰"""
            print(f"--- Node: extract_text_and_analyze ({len(state.get('images',[]))} images) ---")
            images = state.get("images", [])
            if not images:
                return {"error": "ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
            per_episode_texts = []
            per_episode_analyses = []
            errors = []
        
            try:
                # ëª¨ë¸ ì´ˆê¸°í™” (í™˜ê²½ ë³€ìˆ˜ ë“±ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ë„ë¡ ê°œì„  ê°€ëŠ¥)
                # max_tokensë¥¼ ì¶©ë¶„íˆ í¬ê²Œ ì„¤ì • (ê¸´ ì´ë¯¸ì§€ ë¶„ì„ + OCR ê²°ê³¼)
                model = ChatOpenAI(model="gpt-4o", temperature=0, max_tokens=2048, request_timeout=120)
        
                analysis_requests = []
                for i, img in enumerate(images):
                    base64_image = encode_image(img)
                    if not base64_image:
                        errors.append(f"ì—í”¼ì†Œë“œ {i+1}: ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨")
                        analysis_requests.append(None) # ì‹¤íŒ¨í•œ ìš”ì²­ í‘œì‹œ
                        continue
        
                    # í”„ë¡¬í”„íŠ¸ ì •ì˜ (WCAI-P07 ì´ì „ ë‹µë³€ ë‚´ìš© ì°¸ê³ )
                    prompt = """ì´ ì›¹íˆ° ì´ë¯¸ì§€ ì¥ë©´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ë‘ ê°€ì§€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ëª…í™•íˆ êµ¬ë¶„í•´ì„œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        
        ```
        
1. **ì¶”ì¶œëœ í…ìŠ¤íŠ¸:** ì´ë¯¸ì§€ ì•ˆì— ë³´ì´ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸(ë§í’ì„  ì•ˆ ëŒ€ì‚¬, íš¨ê³¼ìŒ, ë°°ê²½ê¸€ì ë“±)ë¥¼ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ëˆ„ë½ ì—†ì´ ìµœëŒ€í•œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
2. **ì‹œê°ì  ë¶„ì„:** ì´ë¯¸ì§€ì˜ ì‹œê°ì  ë‚´ìš©(ì£¼ìš” ë“±ì¥ì¸ë¬¼, ì¸ë¬¼ì˜ í‘œì •ê³¼ í–‰ë™, ë°°ê²½ ì¥ì†Œ, ì „ì²´ì ì¸ ë¶„ìœ„ê¸°, ì¤‘ìš”í•œ ì‹œê°ì  ë‹¨ì„œë‚˜ íš¨ê³¼)ì„ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
ì¶”ì¶œëœ í…ìŠ¤íŠ¸:
[ì—¬ê¸°ì— ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë‚´ìš©]

ì‹œê°ì  ë¶„ì„:
[ì—¬ê¸°ì— ì‹œê°ì  ë¶„ì„ ë‚´ìš©]
"""
prompt_content = [
{"type": "text", "text": prompt},
{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
]
analysis_requests.append(HumanMessage(content=prompt_content))

```
                # MLLM í˜¸ì¶œ (Batch ì²˜ë¦¬ ì‹œë„, ì‹¤íŒ¨ ì‹œ ìˆœì°¨ ì²˜ë¦¬)
                # ì£¼ì˜: LangChainì˜ batchê°€ ëª¨ë“  ëª¨ë¸/í™˜ê²½ì—ì„œ ì•ˆì •ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
                valid_requests = [req for req in analysis_requests if req is not None]
                if valid_requests:
                    try:
                        print(f"Requesting analysis for {len(valid_requests)} images using batch...")
                        results = model.batch(valid_requests, config={"max_concurrency": 5}) # ë™ì‹œì„± ì œí•œ
                    except Exception as batch_err:
                        print(f"Batch processing failed ({batch_err}), falling back to sequential processing...")
                        results = []
                        for req in valid_requests:
                            try:
                                results.append(model.invoke(req))
                            except Exception as invoke_err:
                                print(f"Sequential invoke failed for one image: {invoke_err}")
                                # ì‹¤íŒ¨í•œ ê²½ìš° ì—ëŸ¬ ë©”ì‹œì§€ê°€ ë‹´ê¸´ content ê°ì²´ ìƒì„±
                                from langchain_core.messages import AIMessage
                                results.append(AIMessage(content=f"Error: {invoke_err}"))

                    # ê²°ê³¼ íŒŒì‹± ë° ì €ì¥
                    result_idx = 0
                    for i in range(len(images)):
                        if analysis_requests[i] is None: # ì¸ì½”ë”© ì‹¤íŒ¨ ì¼€ì´ìŠ¤
                            per_episode_texts.append("[ì˜¤ë¥˜: ì´ë¯¸ì§€ ë¡œë“œ/ì¸ì½”ë”© ì‹¤íŒ¨]")
                            per_episode_analyses.append("[ì˜¤ë¥˜: ì´ë¯¸ì§€ ë¡œë“œ/ì¸ì½”ë”© ì‹¤íŒ¨]")
                        elif result_idx < len(results):
                            response = results[result_idx]
                            extracted, visual = parse_mllm_response(response.content)
                            per_episode_texts.append(extracted)
                            per_episode_analyses.append(visual)
                            print(f"  - Image {i+1} analysis parsed.")
                            result_idx += 1
                        else: # API í˜¸ì¶œ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë“±
                            per_episode_texts.append("[ì˜¤ë¥˜: API í˜¸ì¶œ ì‹¤íŒ¨]")
                            per_episode_analyses.append("[ì˜¤ë¥˜: API í˜¸ì¶œ ì‹¤íŒ¨]")
                            errors.append(f"ì—í”¼ì†Œë“œ {i+1}: API í˜¸ì¶œ ì‹¤íŒ¨")

                else: # ëª¨ë“  ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨
                     errors.append("ëª¨ë“  ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨")
                     per_episode_texts = ["[ì˜¤ë¥˜]"] * len(images)
                     per_episode_analyses = ["[ì˜¤ë¥˜]"] * len(images)

            except Exception as e:
                print(f"OCR/ì´ë¯¸ì§€ ë¶„ì„ ë…¸ë“œ ì „ì²´ ì˜¤ë¥˜: {e}")
                errors.append(f"ì „ì²´ ë¶„ì„ ë…¸ë“œ ì˜¤ë¥˜: {str(e)}")
                # ëª¨ë“  ê²°ê³¼ì— ì˜¤ë¥˜ ë°˜ì˜
                per_episode_texts = ["[ì˜¤ë¥˜]"] * len(images)
                per_episode_analyses = ["[ì˜¤ë¥˜]"] * len(images)

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        final_error = "; ".join(errors) if errors else None
        combined_text = "\\n\\n".join([f"--- ì—í”¼ì†Œë“œ {i+1} í…ìŠ¤íŠ¸ ---\\n{text}" for i, text in enumerate(per_episode_texts)])
        combined_analysis = "\\n\\n".join([f"--- ì—í”¼ì†Œë“œ {i+1} ì‹œê° ë¶„ì„ ---\\n{analysis}" for i, analysis in enumerate(per_episode_analyses)])

        print(f"--- Node: extract_text_and_analyze completed. Errors: {final_error} ---")
        return {
            "per_episode_extracted_text": per_episode_texts,
            "per_episode_visual_analysis": per_episode_analyses,
            "sequence_combined_text": combined_text,
            "sequence_combined_analysis": combined_analysis,
            "error": final_error
        }
    ```
* **ì™„ë£Œ ê¸°ì¤€:**
    * ë‹¤ì¤‘ ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬, ê° ì´ë¯¸ì§€ë³„ OCR/ë¶„ì„ ìˆ˜í–‰ ë…¸ë“œ êµ¬í˜„ ì™„ë£Œ.
    * ì•ˆì •ì ì¸ ì‘ë‹µ íŒŒì‹± ë¡œì§ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸.
    * ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ ë° ì¢…í•© í…ìŠ¤íŠ¸ë¡œ ìƒíƒœì— ì €ì¥. ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨.

```

### **WCAI-P08: ì‹œí€€ìŠ¤ ìš”ì•½ ë…¸ë“œ ê°œë°œ (LLM)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 75ë¶„)

- **ì„¤ëª…:** ì—¬ëŸ¬ ì—í”¼ì†Œë“œì— ê±¸ì¹œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì™€ ì‹œê° ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì‹œí€€ìŠ¤ ì „ì²´ì˜ ì¤„ê±°ë¦¬, ìºë¦­í„° ë³€í™” ë“±ì„ ìš”ì•½í•˜ëŠ” LLM ê¸°ë°˜ ë…¸ë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **`summarize_sequence_node` í•¨ìˆ˜ êµ¬í˜„ (`src/agents/webtoon_agent.py`):**
        
        ```python
        # ... (imports, WebtoonSequenceAgentState) ...
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import SystemMessage, HumanMessage
        
        def summarize_sequence_node(state: WebtoonSequenceAgentState) -> Dict:
            """(Node) LLMì„ ì‚¬ìš©í•˜ì—¬ ì‹œí€€ìŠ¤ ì „ì²´ ë‚´ìš©ì„ ìš”ì•½"""
            print(f"--- Node: summarize_sequence ---")
            if state.get("error"):
                print("Skipping summarization due to previous error.")
                return {} # ì´ì „ ì˜¤ë¥˜ ìœ ì§€
        
            combined_text = state.get("sequence_combined_text", "")
            combined_analysis = state.get("sequence_combined_analysis", "")
            titles = state.get("episode_titles", [])
            webtoon_title = state.get("episode_title","") # P09ì—ì„œ webtoon titleë„ ë„£ì–´ì£¼ë©´ ì¢‹ìŒ
        
            if not combined_text and not combined_analysis:
                return {"sequence_summary": "ìš”ì•½í•  ë‚´ìš© ì—†ìŒ", "error": "No content to summarize"}
        
            summary = "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
            error_message = None
        
            try:
                # ìš”ì•½ìš© LLM (ë¹„ìš© íš¨ìœ¨ì  ëª¨ë¸ ì„ íƒ ê°€ëŠ¥)
                model = ChatOpenAI(model="gpt-4o-mini", temperature=0.2, max_tokens=1500, request_timeout=90)
        
                # ì‹œìŠ¤í…œ ë©”ì‹œì§€ (ì—­í•  ë¶€ì—¬)
                system_prompt = "ë‹¹ì‹ ì€ ì›¹íˆ°ì˜ ì—¬ëŸ¬ ì—í”¼ì†Œë“œì— ê±¸ì¹œ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  í•µì‹¬ ì¤„ê±°ë¦¬ë¥¼ ëª…í™•í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ ì›¹íˆ° ë¶„ì„ê°€ì…ë‹ˆë‹¤."
        
                # ì‚¬ìš©ì ë©”ì‹œì§€ (ìƒì„¸í•œ ì§€ì¹¨)
                user_prompt = f"""ë‹¤ìŒì€ ì›¹íˆ° '{webtoon_title}'ì˜ ì—°ì†ëœ {len(titles)}ê°œ ì—í”¼ì†Œë“œ({', '.join(titles)}) ë¶„ëŸ‰ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.
        
                [ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ ì „ì²´ í…ìŠ¤íŠ¸ ìš”ì•½]
                {combined_text[:3000]}... (ë„ˆë¬´ ê¸¸ ê²½ìš° ì¼ë¶€ë§Œ ì œê³µ)
        
                [ì´ë¯¸ì§€ ì‹œê°ì  ë¶„ì„ ìš”ì•½]
                {combined_analysis[:3000]}... (ë„ˆë¬´ ê¸¸ ê²½ìš° ì¼ë¶€ë§Œ ì œê³µ)
        
                ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì´ **ì—°ì†ëœ ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ ì „ì²´**ì— ê±¸ì³ ì¼ì–´ë‚œ **ì£¼ìš” ì‚¬ê±´ì˜ íë¦„(ê¸°ìŠ¹ì „ê²°), í•µì‹¬ ë“±ì¥ì¸ë¬¼ì˜ í–‰ë™/ê°ì • ë³€í™”ë‚˜ ê´€ê³„ ë°œì „, ì¤‘ìš”í•œ ë³µì„ ì´ë‚˜ ë“œëŸ¬ë‚œ ì£¼ì œ** ë“±ì„ í¬í•¨í•˜ì—¬ **í•˜ë‚˜ì˜ í†µí•©ëœ ìš”ì•½ë¬¸(5~7ë¬¸ì¥ ë‚´ì™¸)**ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
                OCR ì˜¤ë¥˜ ê°€ëŠ¥ì„±ì„ ê°ì•ˆí•˜ì—¬ ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨í•˜ê³ , ê²°ê³¼ëŠ” ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                """
        
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt)
                ]
        
                response = model.invoke(messages)
                summary = response.content
                print("Sequence summary generated.")
        
            except Exception as e:
                print(f"Error during sequence summarization: {e}")
                error_message = f"Sequence summarization failed: {str(e)}"
        
            print(f"--- Node: summarize_sequence completed. Errors: {error_message} ---")
            return {
                "sequence_summary": summary,
                "error": error_message or state.get("error") # ê¸°ì¡´ ì˜¤ë¥˜ ìœ ì§€ ë˜ëŠ” ìƒˆ ì˜¤ë¥˜ ì—…ë°ì´íŠ¸
            }
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:** ì‹œí€€ìŠ¤ ì „ì²´ ë‚´ìš©ì„ ì…ë ¥ë°›ì•„ í†µí•© ìš”ì•½ì„ ìƒì„±í•˜ëŠ” LLM ë…¸ë“œ êµ¬í˜„ ì™„ë£Œ. íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±.

### **WCAI-P09: ì›Œí¬í”Œë¡œìš° í†µí•© ë° í…ŒìŠ¤íŠ¸ (ë‹¤ì¤‘ ì—í”¼ì†Œë“œ)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 75ë¶„)

- **ì„¤ëª…:** ê°œë°œëœ ë…¸ë“œë“¤ì„ LangGraphì— ì—°ê²°í•˜ê³ , ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥í•˜ì—¬ ì „ì²´ ì›Œí¬í”Œë¡œìš°ê°€ ë™ì‘í•˜ëŠ”ì§€ í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **`create_webtoon_agent_graph` í•¨ìˆ˜ êµ¬í˜„ ì™„ë£Œ (`src/agents/webtoon_agent.py`):**
        
        ```python
        from langgraph.graph import StateGraph, END
        # ... (import WebtoonSequenceAgentState, node functions) ...
        
        def create_webtoon_agent_graph() -> StateGraph:
            """ì›¹íˆ° ì‹œí€€ìŠ¤ ë¶„ì„ LangGraph ìƒì„± ë° ì„¤ì • (v3)"""
            graph_builder = StateGraph(WebtoonSequenceAgentState)
        
            # ë…¸ë“œ ì¶”ê°€
            graph_builder.add_node("extract_and_analyze", extract_text_and_analyze_node)
            graph_builder.add_node("summarize_sequence", summarize_sequence_node) # ë…¸ë“œ ì´ë¦„ ë³€ê²½ë¨
        
            # ì—£ì§€ ì •ì˜
            graph_builder.set_entry_point("extract_and_analyze")
            graph_builder.add_edge("extract_and_analyze", "summarize_sequence")
            graph_builder.add_edge("summarize_sequence", END)
        
            return graph_builder # ì»´íŒŒì¼ ì „ ë¹Œë” ë°˜í™˜
        
        ```
        
    2. **ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜ êµ¬í˜„ (`src/agents/webtoon_agent.py`ì˜ `analyze_webtoon_sequence`):**
        
        ```python
        from src.utils.data_loader import WebtoonDataLoader
        from langgraph.checkpoint.memory import MemorySaver # ë©”ëª¨ë¦¬ ë‚´ ì²´í¬í¬ì¸íŠ¸ (ì„ íƒì )
        
        # ê·¸ë˜í”„ ë¹Œë” ìƒì„± (ëª¨ë“ˆ ë¡œë“œ ì‹œ)
        graph_builder = create_webtoon_agent_graph()
        
        def analyze_webtoon_sequence(webtoon_id: str, episode_ids: List[str]) -> Dict:
            """ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
            print(f"--- Analyzing sequence for {webtoon_id}: {episode_ids} ---")
            loader = WebtoonDataLoader()
            webtoon_meta = loader.get_webtoon_metadata(webtoon_id)
            sequence_info = loader.get_episode_sequence_info(webtoon_id) # ì œëª© ê°€ì ¸ì˜¤ê¸° ìœ„í•´
        
            if not webtoon_meta or not sequence_info:
                return {"error": f"Metadata not found for {webtoon_id}"}
        
            # ì‹œí€€ìŠ¤ IDì™€ ì œëª© ì¶”ì¶œ (ìš”ì²­ëœ ID ê¸°ì¤€)
            req_episode_titles = [title for ep_id, title in zip(sequence_info[0], sequence_info[1]) if ep_id in episode_ids]
        
            # ì´ë¯¸ì§€ ë¡œë“œ
            images = loader.load_episode_sequence_images(webtoon_id, episode_ids)
            if len(images) != len(episode_ids):
                # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”
                return {"error": f"Failed to load all images for sequence: {episode_ids}"}
        
            # ì´ˆê¸° ìƒíƒœ êµ¬ì„±
            initial_state = WebtoonSequenceAgentState(
                webtoon_id=webtoon_id,
                episode_ids=episode_ids,
                episode_titles=req_episode_titles,
                images=images,
                per_episode_extracted_text=[], # ì´ˆê¸°í™”
                per_episode_visual_analysis=[], # ì´ˆê¸°í™”
                sequence_combined_text="",
                sequence_combined_analysis="",
                sequence_summary="",
                extracted_features=None, # ì´ˆê¸°í™”
                error=None
            )
        
            try:
                # ë©”ëª¨ë¦¬ ë‚´ ì²´í¬í¬ì¸í„° ì‚¬ìš© (ì„ íƒì , ë””ë²„ê¹…/ì¬ì‹œì‘ì— ìœ ìš©)
                memory = MemorySaver()
                webtoon_agent = graph_builder.compile(checkpointer=memory)
        
                # configì— ìŠ¤ë ˆë“œ ID ë“± ì¶”ê°€ ê°€ëŠ¥
                config = {"configurable": {"thread_id": f"{webtoon_id}-{'_'.join(episode_ids)}"}}
                final_state = webtoon_agent.invoke(initial_state, config=config)
        
                print(f"--- Sequence analysis completed for {webtoon_id} ---")
                return final_state
        
            except Exception as e:
                print(f"Agent execution failed for {webtoon_id}: {e}")
                initial_state['error'] = f"Agent execution error: {str(e)}"
                return initial_state
        
        ```
        
    3. **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±/ì‹¤í–‰ (`tests/test_agent_workflow.py`):**
        
        ```python
        import sys, os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        
        from src.agents.webtoon_agent import analyze_webtoon_sequence
        from src.utils.data_loader import WebtoonDataLoader
        from dotenv import load_dotenv
        
        load_dotenv() # API í‚¤ ë¡œë“œ
        
        print("--- Agent Workflow Test (v3: Sequence Analysis) ---")
        loader = WebtoonDataLoader()
        webtoon_ids = loader.get_all_webtoon_ids()
        
        if not webtoon_ids:
            print("RESULT: FAIL - No webtoons found for testing.")
        else:
            test_webtoon_id = webtoon_ids[0] # ì²« ë²ˆì§¸ ì›¹íˆ° í…ŒìŠ¤íŠ¸
            sequence_info = loader.get_episode_sequence_info(test_webtoon_id)
        
            if not sequence_info:
                print(f"RESULT: FAIL - No sequence info found for {test_webtoon_id}")
            else:
                test_episode_ids = sequence_info[0][:3] # ì²« 3ê°œ ì—í”¼ì†Œë“œ í…ŒìŠ¤íŠ¸
                if len(test_episode_ids) < 3:
                     print(f"RESULT: WARN - Fewer than 3 episodes found for {test_webtoon_id}, testing with {len(test_episode_ids)} episodes.")
                if not test_episode_ids:
                     print(f"RESULT: FAIL - No episodes to test for {test_webtoon_id}")
                else:
                    print(f"Testing Webtoon ID: {test_webtoon_id}, Episodes: {test_episode_ids}")
                    try:
                        # ë¶„ì„ ì‹¤í–‰
                        final_state = analyze_webtoon_sequence(test_webtoon_id, test_episode_ids)
        
                        # ê²°ê³¼ í™•ì¸
                        print("\\n--- Final State ---")
                        if final_state.get("error"):
                            print(f"Error occurred: {final_state['error']}")
                            print("RESULT: FAIL - Agent execution resulted in error.")
                        else:
                            print(f"Webtoon ID: {final_state.get('webtoon_id')}")
                            print(f"Episode IDs: {final_state.get('episode_ids')}")
                            print(f"\\nSequence Summary:\\n{final_state.get('sequence_summary', 'N/A')}")
                            print(f"\\nExtracted Text Snippet (Ep 1):\\n{final_state.get('per_episode_extracted_text', ['N/A'])[0][:200]}...")
                            print(f"\\nVisual Analysis Snippet (Ep 1):\\n{final_state.get('per_episode_visual_analysis', ['N/A'])[0][:200]}...")
                            print("\\nRESULT: SUCCESS - Agent workflow executed (check content quality manually).")
        
                    except Exception as e:
                        print(f"\\nRESULT: FAIL - Unexpected error during workflow test: {e}")
        
        ```
        
    4. **í…ŒìŠ¤íŠ¸ ì‹¤í–‰:** í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ `python tests/test_agent_workflow.py` ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸.
- **ì™„ë£Œ ê¸°ì¤€:**
    - ë‹¤ì¤‘ ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ ë¶„ì„ ì›Œí¬í”Œë¡œìš° í†µí•© ì™„ë£Œ.
    - `analyze_webtoon_sequence` í•¨ìˆ˜ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ.
    - í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì •ìƒ ë™ì‘ ë° ìµœì¢… ìƒíƒœì— ì‹œí€€ìŠ¤ ìš”ì•½ ë“± ê²°ê³¼ í¬í•¨ í™•ì¸.

---

## **Phase 2: ê·¸ë˜í”„ ë°ì´í„° êµ¬ì¶• (Sequence Analysis ê¸°ë°˜)**

### **WCAI-G01: ê·¸ë˜í”„ ë°ì´í„° ëª¨ë¸ ì„¤ê³„ ë° ê´€ë¦¬ì êµ¬í˜„** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 90ë¶„)

- **ì„¤ëª…:** ì›¹íˆ°, ì‘ê°€, ì¥ë¥´, íƒœê·¸ ë“± ì£¼ìš” ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ í‘œí˜„í•˜ëŠ” NetworkX ê¸°ë°˜ ê·¸ë˜í”„ ëª¨ë¸ì„ ì„¤ê³„í•˜ê³ , ì´ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ ì •ì˜ (`docs/graph_schema.md`):**
        - Nodes: `Webtoon`(id, title, description, popularity, art_style, ...), `Episode`(id, title, sequence_order), `Character`(id, name, description), `Creator`(id, name), `Platform`(id, name), `Genre`(id, name), `Tag`(id, name), `Theme`(id, name), `PlotPoint`(id, description).
        - Edges: `HAS_EPISODE`(Webtoon->Episode), `APPEARS_IN`(Character->Episode), `CREATED_BY`(Creator->Webtoon), `PUBLISHED_ON`(Webtoon->Platform), `HAS_GENRE`(Webtoon->Genre), `HAS_TAG`(Webtoon->Tag), `HAS_THEME`(Webtoon->Theme), `CONTAINS_PLOT`(Webtoon->PlotPoint), `INTERACTS_WITH`(Character->Character, properties: relationship_type, episode_id), `SIMILAR_TO`(Webtoon->Webtoon, properties: weight, reason).
    2. **`WebtoonGraphModel` í´ë˜ìŠ¤ êµ¬í˜„ (`src/graph/graph_model.py`):**
        
        ```python
        import networkx as nx
        from typing import Dict, Any, Optional
        
        class WebtoonGraphModel:
            def __init__(self):
                # ë°©í–¥ì„±, ë‹¤ì¤‘ ì—£ì§€ í—ˆìš© ê·¸ë˜í”„ ì‚¬ìš© ê³ ë ¤ (ì˜ˆ: ì¸ë¬¼ ê´€ê³„)
                self.graph = nx.MultiDiGraph()
                print("Initialized WebtoonGraphModel with MultiDiGraph.")
        
            def add_node(self, node_id: str, node_type: str, attributes: Optional[Dict[str, Any]] = None):
                """ë…¸ë“œ ì¶”ê°€ ë˜ëŠ” ì—…ë°ì´íŠ¸ (ì†ì„± í¬í•¨)"""
                if attributes is None: attributes = {}
                # typeì€ í•„ìˆ˜ ì†ì„±ìœ¼ë¡œ ì¶”ê°€
                if 'type' not in attributes: attributes['type'] = node_type
                if self.graph.has_node(node_id):
                    # ê¸°ì¡´ ë…¸ë“œ ì†ì„± ì—…ë°ì´íŠ¸
                    self.graph.nodes[node_id].update(attributes)
                else:
                    self.graph.add_node(node_id, **attributes)
                # print(f"Added/Updated node: {node_id} (Type: {node_type})")
        
            def add_edge(self, source_id: str, target_id: str, edge_type: str, attributes: Optional[Dict[str, Any]] = None):
                """ì—£ì§€ ì¶”ê°€ (ì†ì„± í¬í•¨)"""
                if attributes is None: attributes = {}
                if 'type' not in attributes: attributes['type'] = edge_type
                # MultiDiGraphëŠ” ì—¬ëŸ¬ ì—£ì§€ í—ˆìš©, keyë¡œ êµ¬ë¶„ ê°€ëŠ¥ (ì—¬ê¸°ì„  ë‹¨ìˆœ ì¶”ê°€)
                self.graph.add_edge(source_id, target_id, **attributes)
                # print(f"Added edge: {source_id} -[{edge_type}]-> {target_id}")
        
            def get_graph(self) -> nx.MultiDiGraph:
                """NetworkX ê·¸ë˜í”„ ê°ì²´ ë°˜í™˜"""
                return self.graph
        
            def save_graph(self, file_path: str = "data/graph_exports/webtoon_graph.graphml"):
                """ê·¸ë˜í”„ë¥¼ GraphML í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
                try:
                    nx.write_graphml(self.graph, file_path)
                    print(f"Graph saved successfully to {file_path}")
                except Exception as e:
                    print(f"Error saving graph: {e}")
        
            def load_graph(self, file_path: str = "data/graph_exports/webtoon_graph.graphml"):
                """GraphML í˜•ì‹ì—ì„œ ê·¸ë˜í”„ ë¡œë“œ"""
                if os.path.exists(file_path):
                    try:
                        self.graph = nx.read_graphml(file_path)
                        print(f"Graph loaded successfully from {file_path}")
                        return True
                    except Exception as e:
                        print(f"Error loading graph: {e}")
                        # ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¹ˆ ê·¸ë˜í”„ë¡œ ì´ˆê¸°í™”
                        self.graph = nx.MultiDiGraph()
                        return False
                else:
                    print(f"Graph file not found at {file_path}, initializing empty graph.")
                    self.graph = nx.MultiDiGraph()
                    return False
        
        ```
        
    3. **`WebtoonGraphManager` í´ë˜ìŠ¤ êµ¬í˜„ (`src/graph/graph_manager.py`):**
        
        ```python
        import os
        from src.utils.data_loader import WebtoonDataLoader
        from src.graph.graph_model import WebtoonGraphModel
        from typing import Dict, Any
        
        class WebtoonGraphManager:
            def __init__(self, data_dir: str = "data", graph_file: str = "data/graph_exports/webtoon_graph.graphml"):
                self.data_loader = WebtoonDataLoader(data_dir)
                self.graph_model = WebtoonGraphModel()
                self.graph_file = graph_file
                # ì‹œì‘ ì‹œ ê¸°ì¡´ ê·¸ë˜í”„ ë¡œë“œ ì‹œë„
                self.graph_model.load_graph(self.graph_file)
                self.graph = self.graph_model.get_graph() # ë‚´ë¶€ ê·¸ë˜í”„ ì°¸ì¡°
        
            def populate_from_metadata(self):
                """ë©”íƒ€ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì´ˆê¸° ë…¸ë“œ ë° ê´€ê³„ ì¶”ê°€"""
                print("--- Populating graph from metadata ---")
                webtoon_metadata = self.data_loader.webtoon_metadata
        
                for wt in webtoon_metadata:
                    webtoon_id = wt['webtoon_id']
                    # ì›¹íˆ° ë…¸ë“œ ì¶”ê°€/ì—…ë°ì´íŠ¸
                    wt_attrs = {k: v for k, v in wt.items() if k not in ['genre', 'tags', 'creator', 'platform', 'analysis_episode_sequence']}
                    self.graph_model.add_node(webtoon_id, node_type="Webtoon", attributes=wt_attrs)
        
                    # ì¥ë¥´ ë…¸ë“œ ë° ê´€ê³„
                    for genre_name in wt.get('genre', []):
                        genre_id = f"genre_{genre_name.lower().replace(' ','_')}"
                        self.graph_model.add_node(genre_id, node_type="Genre", attributes={"name": genre_name})
                        self.graph_model.add_edge(webtoon_id, genre_id, edge_type="HAS_GENRE")
        
                    # ì‘ê°€ ë…¸ë“œ ë° ê´€ê³„
                    creator_name = wt.get('creator')
                    if creator_name:
                        creator_id = f"creator_{creator_name.lower().replace(' ','_')}"
                        self.graph_model.add_node(creator_id, node_type="Creator", attributes={"name": creator_name})
                        self.graph_model.add_edge(creator_id, webtoon_id, edge_type="CREATED_BY") # ì‘ê°€ -> ì›¹íˆ°
        
                    # í”Œë«í¼ ë…¸ë“œ ë° ê´€ê³„ (ì„ íƒì )
                    platform_name = wt.get('platform')
                    if platform_name:
                        platform_id = f"platform_{platform_name.lower().replace(' ','_')}"
                        self.graph_model.add_node(platform_id, node_type="Platform", attributes={"name": platform_name})
                        self.graph_model.add_edge(webtoon_id, platform_id, edge_type="PUBLISHED_ON")
        
                print(f"Graph populated from metadata. Nodes: {self.graph.number_of_nodes()}, Edges: {self.graph.number_of_edges()}")
        
            def update_graph_with_features(self, webtoon_id: str, features: Dict[str, Any]):
                """ì¶”ì¶œëœ íŠ¹ì§•ìœ¼ë¡œ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸"""
                if not self.graph.has_node(webtoon_id):
                    print(f"Warning: Webtoon node {webtoon_id} not found in graph. Cannot update features.")
                    return
        
                # ì›¹íˆ° ë…¸ë“œ ì†ì„± ì—…ë°ì´íŠ¸ (ì˜ˆ: ë¶„ìœ„ê¸°)
                if 'atmosphere' in features:
                    self.graph.nodes[webtoon_id]['atmosphere'] = features['atmosphere']
        
                # íƒœê·¸ ë…¸ë“œ ë° ê´€ê³„ ì¶”ê°€
                for tag_name in features.get('tags', []):
                    tag_id = f"tag_{tag_name.lower().replace(' ','_')}"
                    self.graph_model.add_node(tag_id, node_type="Tag", attributes={"name": tag_name})
                    self.graph_model.add_edge(webtoon_id, tag_id, edge_type="HAS_TAG")
        
                # ì£¼ì œ ë…¸ë“œ ë° ê´€ê³„ ì¶”ê°€
                for theme_name in features.get('themes', []):
                    theme_id = f"theme_{theme_name.lower().replace(' ','_')}"
                    self.graph_model.add_node(theme_id, node_type="Theme", attributes={"name": theme_name})
                    self.graph_model.add_edge(webtoon_id, theme_id, edge_type="HAS_THEME")
        
                # í”Œë¡¯ í¬ì¸íŠ¸ ë…¸ë“œ ë° ê´€ê³„ ì¶”ê°€ (ì„ íƒì )
                for plot_point in features.get('plot_points', []):
                     # PlotPoint ë…¸ë“œ ID ìƒì„± ë°©ì‹ í•„ìš” (ë‚´ìš© ê¸°ë°˜ í•´ì‹œ ë“±)
                     plot_id = f"plot_{hash(plot_point[:50])}" # ì˜ˆì‹œ
                     self.graph_model.add_node(plot_id, node_type="PlotPoint", attributes={"description": plot_point})
                     self.graph_model.add_edge(webtoon_id, plot_id, edge_type="CONTAINS_PLOT")
        
                # ìºë¦­í„° ì •ë³´ ì—…ë°ì´íŠ¸ (ê³ ê¸‰)
                # ... ìºë¦­í„° ë…¸ë“œ ìƒì„± ë° ê´€ê³„ ì—…ë°ì´íŠ¸ ë¡œì§ ...
        
                print(f"Updated graph for {webtoon_id} with extracted features.")
        
            def add_similarity_edges(self, similarity_threshold=0.7):
                """(ì˜ˆì‹œ) ê³µí†µ íƒœê·¸ ê¸°ë°˜ ìœ ì‚¬ë„ ì—£ì§€ ì¶”ê°€"""
                print("--- Adding similarity edges based on common tags ---")
                webtoon_nodes = [n for n, d in self.graph.nodes(data=True) if d.get('type') == 'Webtoon']
                processed_pairs = set()
                added_edges = 0
        
                for i in range(len(webtoon_nodes)):
                    for j in range(i + 1, len(webtoon_nodes)):
                        wt1_id = webtoon_nodes[i]
                        wt2_id = webtoon_nodes[j]
                        pair = tuple(sorted((wt1_id, wt2_id)))
                        if pair in processed_pairs: continue
        
                        # ê³µí†µ íƒœê·¸ ì°¾ê¸°
                        try:
                            tags1 = set(neighbor for neighbor, data in self.graph[wt1_id].items() if self.graph.nodes[neighbor].get('type') == 'Tag')
                            tags2 = set(neighbor for neighbor, data in self.graph[wt2_id].items() if self.graph.nodes[neighbor].get('type') == 'Tag')
                            common_tags = tags1.intersection(tags2)
                            jaccard_sim = len(common_tags) / len(tags1.union(tags2)) if len(tags1.union(tags2)) > 0 else 0
        
                            if jaccard_sim >= similarity_threshold:
                                 self.graph_model.add_edge(wt1_id, wt2_id, edge_type="SIMILAR_TAGS", attributes={"weight": jaccard_sim, "common": len(common_tags)})
                                 added_edges += 1
                        except KeyError: # ì´ì›ƒì´ ì—†ëŠ” ê²½ìš° ë“±
                             continue
                        finally:
                             processed_pairs.add(pair)
        
                print(f"Added {added_edges} SIMILAR_TAGS edges (threshold={similarity_threshold}).")
        
            def save(self):
                 """í˜„ì¬ ê·¸ë˜í”„ ì €ì¥"""
                 self.graph_model.save_graph(self.graph_file)
        
            # ì‹œê°í™” í•¨ìˆ˜ëŠ” G04ì—ì„œ êµ¬ì²´í™”
            def visualize_graph(self, output_file: Optional[str] = None):
                 print(f"Graph visualization function called. Target: {output_file or 'default HTML'}")
                 # WCAI-G04ì—ì„œ PyVis ë¡œì§ êµ¬í˜„
                 pass
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:**
    - ìƒì„¸ ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ ì •ì˜ ì™„ë£Œ.
    - `WebtoonGraphModel` í´ë˜ìŠ¤ êµ¬í˜„ (NetworkX ê¸°ë°˜, ì €ì¥/ë¡œë“œ ê¸°ëŠ¥ í¬í•¨).
    - `WebtoonGraphManager` í´ë˜ìŠ¤ êµ¬í˜„ (ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì´ˆê¸° ê·¸ë˜í”„ êµ¬ì¶• ê¸°ëŠ¥ í¬í•¨).

### **WCAI-G02: ì›¹íˆ° íŠ¹ì§• ì¶”ì¶œ ê¸°ëŠ¥ êµ¬í˜„ (Sequence ê¸°ë°˜)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 120ë¶„)

- **ì„¤ëª…:** ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·¸ë˜í”„ì— ì¶”ê°€í•  ì •ì œëœ íŠ¹ì§•(ìºë¦­í„° ê´€ê³„ ë³€í™”, í”Œë¡¯ í¬ì¸íŠ¸, í…Œë§ˆ ë³€í™” ë“±)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **`FeatureExtractor` í´ë˜ìŠ¤/ëª¨ë“ˆ êµ¬í˜„ (`src/analysis/feature_extractor.py`):**
        
        ```python
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import SystemMessage, HumanMessage
        from typing import Dict, List, Any, Optional
        import json
        
        class FeatureExtractor:
            def __init__(self, model_name="gpt-4o-mini", temperature=0.1, request_timeout=60):
                self.llm = ChatOpenAI(model=model_name, temperature=temperature, request_timeout=request_timeout)
                print(f"Initialized FeatureExtractor with model: {model_name}")
        
            def extract_features_from_sequence(self,
                                               sequence_summary: str,
                                               webtoon_metadata: Dict[str, Any]) -> Optional[Dict[str, Any]]:
                """ì‹œí€€ìŠ¤ ìš”ì•½ê³¼ ë©”íƒ€ë°ì´í„°ë¡œë¶€í„° êµ¬ì¡°í™”ëœ íŠ¹ì§• ì¶”ì¶œ"""
                print(f"--- Extracting features for: {webtoon_metadata.get('title', 'N/A')} ---")
                if not sequence_summary:
                    print("Warning: Empty sequence summary provided.")
                    return None
        
                system_prompt = """ë‹¹ì‹ ì€ ì›¹íˆ° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì›¹íˆ° ì‹œí€€ìŠ¤ ìš”ì•½ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ í•­ëª©ë“¤ì„ **JSON í˜•ì‹**ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ê° í•­ëª©ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸([]) ë˜ëŠ” null ê°’ì„ ì‚¬ìš©í•˜ì„¸ìš”:
                1.  `main_characters`: ì‹œí€€ìŠ¤ì— ì¤‘ìš”í•˜ê²Œ ë“±ì¥í•˜ëŠ” ì¸ë¬¼ ì´ë¦„ ëª©ë¡ (List[str]).
                2.  `character_relationships`: ì£¼ìš” ì¸ë¬¼ ê°„ì˜ ê´€ê³„ ë³€í™”ë‚˜ íŠ¹ì§•ì  ìƒí˜¸ì‘ìš©ì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª… (str).
                3.  `plot_points`: ì‹œí€€ìŠ¤ ë‚´ í•µì‹¬ ì‚¬ê±´ ë˜ëŠ” ì „í™˜ì  ìš”ì•½ ëª©ë¡ (List[str]).
                4.  `themes`: ì‹œí€€ìŠ¤ì—ì„œ ë“œëŸ¬ë‚˜ëŠ” ì£¼ìš” ì£¼ì œë‚˜ í…Œë§ˆ ëª©ë¡ (List[str]).
                5.  `atmosphere`: ì‹œí€€ìŠ¤ì˜ ì „ì²´ì ì¸ ë¶„ìœ„ê¸° (ì˜ˆ: ê¸´ì¥ê° ë„˜ì¹¨, ì½”ë¯¹í•¨, ê°ì„±ì  ë“±) (str).
                6.  `content_tags`: ë‚´ìš©ì„ ì˜ ë‚˜íƒ€ë‚´ëŠ” ì¶”ê°€ì ì¸ í‚¤ì›Œë“œ íƒœê·¸ ëª©ë¡ (List[str]). ê¸°ì¡´ ì¥ë¥´/íƒœê·¸ ì™¸ ë‚´ìš© ê¸°ë°˜ íƒœê·¸.
                """
        
                user_prompt = f"""ë¶„ì„ ëŒ€ìƒ ì›¹íˆ° ì‹œí€€ìŠ¤ ì •ë³´:
                - ì œëª©: {webtoon_metadata.get('title', 'N/A')}
                - ì¥ë¥´: {webtoon_metadata.get('genre', [])}
                - ê¸°ì¡´ íƒœê·¸: {webtoon_metadata.get('tags', [])}
                - ì‹œí€€ìŠ¤ ìš”ì•½:
                {sequence_summary}
        
                ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON í˜•ì‹ì˜ íŠ¹ì§• ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
                """
        
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt)
                ]
        
                try:
                    response = self.llm.invoke(messages)
                    content = response.content.strip()
                    print("LLM response received for feature extraction.")
        
                    # LLM ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ ì¶”ì¶œ ì‹œë„ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ë“± ì œê±°)
                    json_match = re.search(r"```json\\s*([\\s\\S]*?)\\s*```", content)
                    if json_match:
                        json_str = json_match.group(1)
                    else: # JSON ì½”ë“œ ë¸”ë¡ì´ ì—†ì„ ê²½ìš°, ì „ì²´ ì‘ë‹µì´ JSONì´ë¼ê³  ê°€ì •
                         json_str = content
        
                    # JSON íŒŒì‹±
                    extracted_data = json.loads(json_str)
                    print("Successfully parsed features from LLM response.")
                    # ê°„ë‹¨í•œ ìœ íš¨ì„± ê²€ì‚¬ (í•„ìš”í•œ í‚¤ ì¡´ì¬ ì—¬ë¶€ ë“±)
                    required_keys = ['main_characters', 'character_relationships', 'plot_points', 'themes', 'atmosphere', 'content_tags']
                    if all(key in extracted_data for key in required_keys):
                        return extracted_data
                    else:
                         print(f"Warning: Missing required keys in parsed JSON. Parsed: {extracted_data}")
                         return None # ë¶ˆì™„ì „í•œ ë°ì´í„° ì²˜ë¦¬
        
                except json.JSONDecodeError:
                    print(f"Error: Failed to decode JSON from LLM response.\\nResponse:\\n{content}")
                    return None
                except Exception as e:
                    print(f"Error during feature extraction LLM call: {e}")
                    return None
        
        ```
        
    2. **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (`tests/test_feature_extractor.py`):**
        - ìƒ˜í”Œ ì‹œí€€ìŠ¤ ìš”ì•½ ë° ë©”íƒ€ë°ì´í„° ì¤€ë¹„.
        - `FeatureExtractor` ì¸ìŠ¤í„´ìŠ¤ ìƒì„±.
        - `extract_features_from_sequence` í˜¸ì¶œ.
        - ë°˜í™˜ëœ ë”•ì…”ë„ˆë¦¬ ë‚´ìš© í™•ì¸ (JSON êµ¬ì¡°, ì˜ˆìƒ í‚¤ ì¡´ì¬ ì—¬ë¶€ ë“±).
- **ì™„ë£Œ ê¸°ì¤€:**
    - ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ë¡œë¶€í„° êµ¬ì¡°í™”ëœ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ êµ¬í˜„ ì™„ë£Œ.
    - LLM ì‘ë‹µ(JSON) íŒŒì‹± ë° ì˜¤ë¥˜ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„.
    - í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì •ìƒ ë™ì‘ ë° ìœ íš¨í•œ JSON ì¶œë ¥ í™•ì¸.

### **WCAI-G03: ê·¸ë˜í”„ ìë™ êµ¬ì¶• íŒŒì´í”„ë¼ì¸ êµ¬í˜„ (Sequence ê¸°ë°˜)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 150ë¶„)

- **ì„¤ëª…:** ì „ì²´ ì›¹íˆ° ë°ì´í„°ì— ëŒ€í•´ ì‹œí€€ìŠ¤ ë¶„ì„ -> íŠ¹ì§• ì¶”ì¶œ -> ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ê´€ê³„(ì—£ì§€) ìƒì„± ë¡œì§ì´ í•µì‹¬ì…ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (`scripts/build_graph_pipeline.py`):**
        
        ```python
        import sys, os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        
        from src.utils.data_loader import WebtoonDataLoader
        from src.agents.webtoon_agent import analyze_webtoon_sequence # ì‹œí€€ìŠ¤ ë¶„ì„ í•¨ìˆ˜
        from src.analysis.feature_extractor import FeatureExtractor # íŠ¹ì§• ì¶”ì¶œê¸°
        from src.graph.graph_manager import WebtoonGraphManager # ê·¸ë˜í”„ ê´€ë¦¬ì
        from dotenv import load_dotenv
        import json
        import time
        
        # ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë””ë ‰í† ë¦¬ (ìºì‹± ë˜ëŠ” ì¤‘ê°„ ê²°ê³¼ ì €ì¥ìš©)
        RESULTS_DIR = "data/analysis_results"
        FEATURES_DIR = os.path.join(RESULTS_DIR, "features")
        GRAPH_FILE = "data/graph_exports/webtoon_knowledge_graph.graphml"
        
        os.makedirs(FEATURES_DIR, exist_ok=True)
        
        def run_pipeline():
            load_dotenv() # API í‚¤ ë¡œë“œ
            start_time = time.time()
        
            print("--- Starting Graph Build Pipeline ---")
            loader = WebtoonDataLoader()
            graph_manager = WebtoonGraphManager(graph_file=GRAPH_FILE)
            feature_extractor = FeatureExtractor() # LLM ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œê¸° ì´ˆê¸°í™”
        
            # 1. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì´ˆê¸° ê·¸ë˜í”„ ìƒì„±
            graph_manager.populate_from_metadata()
        
            webtoon_ids = loader.get_all_webtoon_ids()
            print(f"Processing {len(webtoon_ids)} webtoons...")
        
            for i, webtoon_id in enumerate(webtoon_ids):
                print(f"\\n[{i+1}/{len(webtoon_ids)}] Processing Webtoon: {webtoon_id}")
                webtoon_meta = loader.get_webtoon_metadata(webtoon_id)
                sequence_info = loader.get_episode_sequence_info(webtoon_id)
        
                if not webtoon_meta or not sequence_info or not sequence_info[0]:
                    print(f"Skipping {webtoon_id}: Missing metadata or sequence info.")
                    continue
        
                episode_ids = sequence_info[0] # ë¶„ì„í•  ì—í”¼ì†Œë“œ ID ë¦¬ìŠ¤íŠ¸
        
                # 2. ì‹œí€€ìŠ¤ ë¶„ì„ ì‹¤í–‰ (ê²°ê³¼ ìºì‹± ë¡œì§ ì¶”ê°€ ê¶Œì¥)
                # ì˜ˆ: ì´ë¯¸ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ì‹¤í–‰ í›„ ì €ì¥
                # sequence_result_file = os.path.join(RESULTS_DIR, f"{webtoon_id}_sequence_analysis.json")
                # if os.path.exists(sequence_result_file):
                #     with open(sequence_result_file, 'r', encoding='utf-8') as f: sequence_result = json.load(f)
                # else:
                sequence_result = analyze_webtoon_sequence(webtoon_id, episode_ids)
                #     # ë¶„ì„ ê²°ê³¼ ì €ì¥ (ì„ íƒì )
                #     # with open(sequence_result_file, 'w', encoding='utf-8') as f: json.dump(sequence_result, f, ensure_ascii=False, indent=2)
        
                if sequence_result.get("error"):
                    print(f"Skipping {webtoon_id}: Sequence analysis failed - {sequence_result['error']}")
                    continue
        
                # 3. íŠ¹ì§• ì¶”ì¶œ ì‹¤í–‰
                features_file = os.path.join(FEATURES_DIR, f"{webtoon_id}_features.json")
                if os.path.exists(features_file):
                     with open(features_file, 'r', encoding='utf-8') as f: features = json.load(f)
                else:
                     features = feature_extractor.extract_features_from_sequence(
                         sequence_summary=sequence_result.get("sequence_summary", ""),
                         webtoon_metadata=webtoon_meta
                     )
                     if features:
                         with open(features_file, 'w', encoding='utf-8') as f: json.dump(features, f, ensure_ascii=False, indent=2)
                     else:
                         print(f"Skipping feature update for {webtoon_id}: Feature extraction failed.")
                         features = {} # ë¹ˆ ê°’ìœ¼ë¡œ ì²˜ë¦¬
        
                # 4. ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ (ë…¸ë“œ ì†ì„± ë° íŠ¹ì§• ê¸°ë°˜ ì—£ì§€)
                if features:
                    graph_manager.update_graph_with_features(webtoon_id, features)
                else: # íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ íƒœê·¸ë¼ë„ ì¶”ê°€
                     tags_from_meta = webtoon_meta.get('tags', [])
                     if tags_from_meta:
                          graph_manager.update_graph_with_features(webtoon_id, {"tags": tags_from_meta})
        
            # 5. ëª¨ë“  ì›¹íˆ° ì²˜ë¦¬ í›„, ê´€ê³„(ìœ ì‚¬ë„) ì—£ì§€ ìƒì„±
            graph_manager.add_similarity_edges(similarity_threshold=0.3) # ì˜ˆì‹œ: ê³µí†µ íƒœê·¸ 30% ì´ìƒ ìœ ì‚¬
        
            # 6. ìµœì¢… ê·¸ë˜í”„ ì €ì¥
            graph_manager.save()
        
            end_time = time.time()
            print(f"--- Graph Build Pipeline Finished ---")
            print(f"Total time: {end_time - start_time:.2f} seconds")
            print(f"Final Graph: Nodes={graph_manager.graph.number_of_nodes()}, Edges={graph_manager.graph.number_of_edges()}")
            print(f"Graph saved to: {GRAPH_FILE}")
        
        if __name__ == "__main__":
            run_pipeline()
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:**
    - ì „ì²´ ìƒ˜í”Œ ì›¹íˆ°ì— ëŒ€í•œ ì‹œí€€ìŠ¤ ë¶„ì„->íŠ¹ì§• ì¶”ì¶œ->ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ ìë™í™” íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ì™„ë£Œ.
    - íŠ¹ì§• ê¸°ë°˜ ê´€ê³„(ìœ ì‚¬ë„) ìƒì„± ë¡œì§ êµ¬í˜„ (ìµœì†Œ 1ê°€ì§€ ë°©ì‹).
    - íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í›„ ìµœì¢… ê·¸ë˜í”„ íŒŒì¼(`.graphml`) ìƒì„± í™•ì¸.

### **WCAI-G04: ê·¸ë˜í”„ ì‹œê°í™” ê¸°ëŠ¥ êµ¬í˜„** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 60ë¶„)

- **ì„¤ëª…:** êµ¬ì¶•ëœ ì›¹íˆ° ì§€ì‹ ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•˜ì—¬ ê´€ê³„ë¥¼ ì§ê´€ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **ì‹œê°í™” í•¨ìˆ˜ êµ¬í˜„ (`src/graph/graph_manager.py` ë‚´ `visualize_graph` ë©”ì„œë“œ):**
        
        ```python
        from pyvis.network import Network
        import networkx as nx
        import os
        from typing import Optional
        
        # ... (WebtoonGraphManager í´ë˜ìŠ¤ ë‚´) ...
        def visualize_graph(self, output_file: str = "data/graph_exports/webtoon_graph_visualization.html", physics: bool = True):
            """ê·¸ë˜í”„ë¥¼ PyVisë¥¼ ì‚¬ìš©í•˜ì—¬ HTML íŒŒì¼ë¡œ ì‹œê°í™”"""
            print(f"--- Generating graph visualization to {output_file} ---")
            if not self.graph or self.graph.number_of_nodes() == 0:
                print("Graph is empty, cannot visualize.")
                return
        
            # PyVis ë„¤íŠ¸ì›Œí¬ ê°ì²´ ìƒì„±
            net = Network(notebook=False, height="800px", width="100%", directed=isinstance(self.graph, nx.DiGraph))
        
            # ë¬¼ë¦¬ ì—”ì§„ ì„¤ì • (ë…¸ë“œê°€ ë§ì„ ê²½ìš° False ê³ ë ¤)
            if physics:
                net.show_buttons(filter_=['physics']) # ë¬¼ë¦¬ íš¨ê³¼ ì¡°ì ˆ ë²„íŠ¼ í‘œì‹œ
            else:
                net.force_atlas_2based() # ë¬¼ë¦¬ íš¨ê³¼ ë¹„í™œì„±í™” ì‹œ ë ˆì´ì•„ì›ƒ ì•Œê³ ë¦¬ì¦˜
        
            # ë…¸ë“œ ì¶”ê°€ ë° ìŠ¤íƒ€ì¼ë§
            node_colors = {"Webtoon": "#1f77b4", "Genre": "#ff7f0e", "Tag": "#2ca02c", "Creator": "#d62728", "Theme": "#9467bd", "PlotPoint": "#8c564b", "Platform": "#e377c2"}
            node_sizes = {"Webtoon": 25, "Creator": 15, "Genre": 10, "Tag": 8, "Theme": 8, "PlotPoint": 8, "Platform": 10}
        
            for node, data in self.graph.nodes(data=True):
                node_type = data.get('type', 'Unknown')
                label = data.get('title') or data.get('name') or data.get('value') or str(node) # í‘œì‹œë  ë¼ë²¨
                size = node_sizes.get(node_type, 5)
                color = node_colors.get(node_type, "#7f7f7f")
                title_attr = f"ID: {node}\\nType: {node_type}\\n" + "\\n".join([f"{k}: {v}" for k, v in data.items() if k not in ['type']]) # ë§ˆìš°ìŠ¤ ì˜¤ë²„ ì‹œ ì •ë³´
        
                net.add_node(str(node), label=label, title=title_attr, size=size, color=color)
        
            # ì—£ì§€ ì¶”ê°€ ë° ìŠ¤íƒ€ì¼ë§
            for u, v, data in self.graph.edges(data=True):
                edge_type = data.get('type', '')
                weight = data.get('weight', 1.0)
                title_attr = f"Type: {edge_type}\\nWeight: {weight:.2f}"
                # ì—£ì§€ ë‘ê»˜/ìƒ‰ìƒ ì¡°ì ˆ ê°€ëŠ¥
                edge_width = max(0.5, weight * 2) if edge_type.startswith("SIMILAR") else 1.0
        
                net.add_edge(str(u), str(v), title=title_attr, width=edge_width)
        
            # HTML íŒŒì¼ ì €ì¥
            try:
                # íŒŒì¼ ê²½ë¡œì˜ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
                output_dir = os.path.dirname(output_file)
                if not os.path.exists(output_dir):
                    os.makedirs(output_dir)
                net.save_graph(output_file)
                print(f"Graph visualization saved to {output_file}")
            except Exception as e:
                print(f"Error saving graph visualization: {e}")
        
        ```
        
    2. **íŒŒì´í”„ë¼ì¸(G03) ì™„ë£Œ í›„ ë˜ëŠ” ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ í˜¸ì¶œ:** `graph_manager.visualize_graph()` ì‹¤í–‰.
- **ì™„ë£Œ ê¸°ì¤€:**
    - êµ¬ì¶•ëœ ê·¸ë˜í”„ë¥¼ PyVisë¡œ ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ.
    - ë…¸ë“œ/ì—£ì§€ ìŠ¤íƒ€ì¼ë§ ì ìš©.
    - ìƒí˜¸ì‘ìš© ê°€ëŠ¥í•œ HTML ì‹œê°í™” íŒŒì¼ ì •ìƒ ìƒì„± í™•ì¸.

## **Phase 3: PathRAG í†µí•© ë° ë¶„ì„/ì¶”ì²œ ê¸°ëŠ¥ êµ¬í˜„ (Sequence ê¸°ë°˜)**

### **WCAI-PR01: PathRAG ì„¤ì • ë° ë°ì´í„° ì¸ë±ì‹± (Sequence ê¸°ë°˜)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 120ë¶„)

- **ì„¤ëª…:** PathRAG ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì •í•˜ê³ , ì›¹íˆ° ë©”íƒ€ë°ì´í„°ì™€ **ì‹œí€€ìŠ¤ ë¶„ì„ ê¸°ë°˜ì˜ ìƒì„¸ ì •ë³´**ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì¸ë±ì‹±(ì‚½ì…)í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **`WebtoonPathRAG` í´ë˜ìŠ¤ êµ¬í˜„ (`src/graph/pathrag_integration.py`):**
        
        ```python
        import os
        import json
        from typing import Dict, List, Any, Optional
        # PathRAG ë¼ì´ë¸ŒëŸ¬ë¦¬ import í™•ì¸ (ì„¤ì¹˜ ê²½ë¡œì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        try:
             from PathRAG import PathRAG, QueryParam
             from PathRAG.llm import gpt_4o_mini_complete # ë˜ëŠ” ë‹¤ë¥¸ LLM í•¨ìˆ˜
        except ImportError as e:
             print(f"Error importing PathRAG: {e}. Make sure PathRAG is installed correctly.")
             # í•„ìš”í•œ ê²½ìš° sys.path ì¡°ì • ë˜ëŠ” ì˜ˆì™¸ ì²˜ë¦¬
             sys.exit(1) # PathRAG ì—†ìœ¼ë©´ ì‹¤í–‰ ë¶ˆê°€
        from src.utils.data_loader import WebtoonDataLoader # ë°ì´í„° ë¡œë”©ìš©
        # íŠ¹ì§•, ìš”ì•½ ë¡œë”© ê²½ë¡œ ì •ì˜
        FEATURES_DIR = "data/analysis_results/features"
        # SUMMARY_DIR = "data/analysis_results" # í•„ìš”ì‹œ ìš”ì•½ë„ ë³„ë„ ì €ì¥
        
        class WebtoonPathRAG:
            def __init__(self,
                         working_dir: str = "./pathrag_working_dir",
                         model_func = gpt_4o_mini_complete, # PathRAG ë‚´ë¶€ LLM ì„¤ì •
                         api_key: Optional[str] = None):
        
                if api_key: os.environ["OPENAI_API_KEY"] = api_key
                if not os.getenv("OPENAI_API_KEY"): raise ValueError("OPENAI_API_KEY must be set.")
        
                self.working_dir = working_dir
                if not os.path.exists(working_dir): os.makedirs(working_dir)
        
                print(f"Initializing PathRAG with working_dir: {working_dir}")
                self.rag = PathRAG(working_dir=working_dir, llm_model_func=model_func)
                self.loader = WebtoonDataLoader() # ë©”íƒ€ë°ì´í„° ë¡œë”©ìš©
        
            def _generate_webtoon_text(self, webtoon_id: str) -> Optional[str]:
                """PathRAG ì¸ë±ì‹±ì„ ìœ„í•œ ìƒì„¸ í…ìŠ¤íŠ¸ ìƒì„±"""
                metadata = self.loader.get_webtoon_metadata(webtoon_id)
                if not metadata: return None
        
                # íŠ¹ì§• ë°ì´í„° ë¡œë“œ
                features = {}
                feature_file = os.path.join(FEATURES_DIR, f"{webtoon_id}_features.json")
                if os.path.exists(feature_file):
                    try:
                        with open(feature_file, 'r', encoding='utf-8') as f: features = json.load(f)
                    except json.JSONDecodeError: print(f"Warning: Could not decode feature file {feature_file}")
        
                # ì‹œí€€ìŠ¤ ìš”ì•½ ë¡œë“œ (Agent ì‹¤í–‰ ê²°ê³¼ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜, ë³„ë„ ì €ì¥ëœ íŒŒì¼ ë¡œë“œ)
                # ì—¬ê¸°ì„œëŠ” ìš”ì•½ì´ íŠ¹ì§•ì— í¬í•¨ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜, ë³„ë„ ë¡œì§ í•„ìš”
                # sequence_summary = features.get("sequence_summary", "") # ì˜ˆì‹œ
                # ì‹¤ì œë¡œëŠ” G03 íŒŒì´í”„ë¼ì¸ì—ì„œ ì €ì¥/ê´€ë¦¬ëœ ìš”ì•½ ë¡œë“œ í•„ìš”
                sequence_summary = "ì‹œí€€ìŠ¤ ìš”ì•½ ë¡œë”© ë¡œì§ í•„ìš”" # Placeholder
        
                # ìƒì„¸ í…ìŠ¤íŠ¸ ìƒì„±
                text = f"ì›¹íˆ° ì •ë³´: {webtoon_id}\\n"
                text += f"ì œëª©: {metadata.get('title', 'N/A')}\\n"
                text += f"ì‘ê°€: {metadata.get('creator', 'N/A')}\\n"
                text += f"í”Œë«í¼: {metadata.get('platform', 'N/A')}\\n"
                text += f"ì¥ë¥´: {', '.join(metadata.get('genre', []))}\\n"
                text += f"ê¸°ë³¸ íƒœê·¸: {', '.join(metadata.get('tags', []))}\\n"
                text += f"ì•„íŠ¸ ìŠ¤íƒ€ì¼: {metadata.get('art_style', 'N/A')}\\n"
                text += f"ì¸ê¸°ë„: {metadata.get('popularity_score', 'N/A')}\\n"
                text += f"ë¡œë§¨ìŠ¤ í¬í•¨ ì—¬ë¶€: {'ì˜ˆ' if metadata.get('is_romance') else 'ì•„ë‹ˆì˜¤'}\\n"
                text += f"ì„¤ëª…: {metadata.get('description', 'N/A')}\\n"
                text += f"\\në¶„ì„ëœ ì‹œí€€ìŠ¤ ìš”ì•½:\\n{sequence_summary}\\n" # ì‹œí€€ìŠ¤ ìš”ì•½ í¬í•¨
                text += f"\\nì¶”ì¶œëœ ì£¼ìš” íŠ¹ì§•:\\n"
                text += f"- ì£¼ìš” ë“±ì¥ì¸ë¬¼: {', '.join(features.get('main_characters', []))}\\n"
                text += f"- ìºë¦­í„° ê´€ê³„/ë³€í™”: {features.get('character_relationships', 'N/A')}\\n"
                text += f"- í•µì‹¬ í”Œë¡¯ í¬ì¸íŠ¸: {'; '.join(features.get('plot_points', []))}\\n"
                text += f"- ì£¼ìš” ì£¼ì œ/í…Œë§ˆ: {', '.join(features.get('themes', []))}\\n"
                text += f"- ì „ì²´ ë¶„ìœ„ê¸°: {features.get('atmosphere', 'N/A')}\\n"
                text += f"- ë‚´ìš© ê¸°ë°˜ íƒœê·¸: {', '.join(features.get('content_tags', []))}\\n"
        
                return text.strip()
        
            def build_index_from_metadata(self, force_rebuild: bool = False):
                """ëª¨ë“  ì›¹íˆ° ë°ì´í„° ì¸ë±ì‹± (ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ ì˜µì…˜)"""
                print("--- Building PathRAG index ---")
                if force_rebuild and os.path.exists(self.working_dir):
                    import shutil
                    print(f"Removing existing index at {self.working_dir}")
                    shutil.rmtree(self.working_dir)
                    os.makedirs(self.working_dir)
                    # PathRAG ì¬ì´ˆê¸°í™” í•„ìš”í•  ìˆ˜ ìˆìŒ
                    self.rag = PathRAG(working_dir=self.working_dir, llm_model_func=gpt_4o_mini_complete)
        
                webtoon_ids = self.loader.get_all_webtoon_ids()
                indexed_count = 0
                for webtoon_id in webtoon_ids:
                    print(f"Generating text for {webtoon_id}...")
                    webtoon_text = self._generate_webtoon_text(webtoon_id)
                    if webtoon_text:
                        try:
                            print(f"Inserting data for {webtoon_id} into PathRAG...")
                            self.rag.insert(webtoon_text) # PathRAGì— í…ìŠ¤íŠ¸ ì‚½ì…
                            indexed_count += 1
                        except Exception as e:
                            print(f"Error inserting {webtoon_id} into PathRAG: {e}")
                    else:
                        print(f"Skipping {webtoon_id}: Could not generate text.")
                print(f"--- PathRAG indexing complete. Indexed {indexed_count}/{len(webtoon_ids)} webtoons. ---")
        
            def query(self, question: str, mode: str = "hybrid", max_paths: int = 5, k: int = 5) -> Any:
                """PathRAG ì¿¼ë¦¬ ì‹¤í–‰"""
                print(f"--- PathRAG Query ---")
                print(f"Question: {question}")
                print(f"Mode: {mode}, Max Paths: {max_paths}, K: {k}")
                try:
                    # QueryParam ì„¤ì • í™•ì¸ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                    param = QueryParam(mode=mode, k=k, max_path_num=max_paths)
                    result = self.rag.query(question, param=param)
                    print("PathRAG Query successful.")
                    return result
                except Exception as e:
                    print(f"Error during PathRAG query: {e}")
                    return f"Error: {str(e)}"
        
        ```
        
    2. **ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ë° ì‹¤í–‰ (`scripts/build_pathrag_index.py`):**
        
        ```python
        import sys, os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from src.graph.pathrag_integration import WebtoonPathRAG
        from dotenv import load_dotenv
        
        if __name__ == "__main__":
            load_dotenv()
            # API í‚¤ ì§ì ‘ ì „ë‹¬ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ í™•ì¸
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                 print("Error: OPENAI_API_KEY not set.")
            else:
                 rag_builder = WebtoonPathRAG(api_key=api_key)
                 # force_rebuild=Trueë¡œ ì„¤ì •í•˜ë©´ ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ í›„ ì¬ìƒì„±
                 rag_builder.build_index_from_metadata(force_rebuild=False)
        
        ```
        
    3. **ì‹¤í–‰:** í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ `python scripts/build_pathrag_index.py` ì‹¤í–‰. `pathrag_working_dir`ì— íŒŒì¼ ìƒì„± í™•ì¸.
- **ì™„ë£Œ ê¸°ì¤€:**
    - `WebtoonPathRAG` í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ (ì´ˆê¸°í™”, í…ìŠ¤íŠ¸ ìƒì„±, ì¸ë±ì‹±, ì¿¼ë¦¬ ë©”ì„œë“œ).
    - ì „ì²´ ì›¹íˆ° ë°ì´í„°ì— ëŒ€í•œ ìƒì„¸ í…ìŠ¤íŠ¸ ìƒì„± ë° PathRAG ì¸ë±ì‹± ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ.
    - ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì„±ê³µ í™•ì¸.

### **WCAI-PR02: PathRAG ê¸°ë°˜ ë¶„ì„/ì¶”ì²œ ê¸°ëŠ¥ êµ¬í˜„ (Sequence ê¸°ë°˜)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 150ë¶„)

- **ì„¤ëª…:** PathRAG ì¿¼ë¦¬ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ì‹œí€€ìŠ¤ ë‚´ìš©ì„ ë°˜ì˜í•œ ë¶„ì„/ì¶”ì²œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **ì¿¼ë¦¬ ì²˜ë¦¬ ëª¨ë“ˆ/í´ë˜ìŠ¤ êµ¬í˜„ (`src/analysis/pathrag_analyzer.py`):**
        
        ```python
        from src.graph.pathrag_integration import WebtoonPathRAG
        from typing import Dict, List, Any, Optional
        
        class PathRAGAnalyzer:
            def __init__(self, pathrag_instance: WebtoonPathRAG):
                self.pathrag = pathrag_instance
                print("Initialized PathRAGAnalyzer.")
        
            def _post_process_result(self, result: Any) -> str:
                """PathRAG ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì  í…ìŠ¤íŠ¸ë¡œ í›„ì²˜ë¦¬"""
                # PathRAG ê²°ê³¼ í˜•ì‹ì— ë”°ë¼ íŒŒì‹±/ì •ë¦¬ í•„ìš”
                # ì˜ˆì‹œ: resultê°€ í…ìŠ¤íŠ¸ ë¬¸ìì—´ì´ë¼ê³  ê°€ì •
                if isinstance(result, str):
                    # ê°„ë‹¨íˆ ì•ë’¤ ê³µë°± ì œê±° ë° ì •ë¦¬
                    return result.strip()
                # TODO: PathRAG ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì‹¤ì œ ë°˜í™˜ í˜•ì‹ í™•ì¸ í›„ êµ¬í˜„
                return str(result) # ê¸°ë³¸ ë³€í™˜
        
            def find_popular_pattern(self, genre: Optional[str] = None, top_n: int = 3) -> str:
                """ì¸ê¸° ì›¹íˆ° íŒ¨í„´ ë¶„ì„"""
                query = f"ìƒìœ„ {top_n}ê°œì˜ ì¸ê¸° ì›¹íˆ°ë“¤ì˜ ê³µí†µì ì¸ íŠ¹ì§•ì´ë‚˜ ì„±ê³µ ìš”ì¸ì„ ë¶„ì„í•´ì¤˜."
                if genre:
                    query = f"'{genre}' ì¥ë¥´ " + query
                print(f"Executing popular pattern query: {query}")
                # 'graph' ëª¨ë“œê°€ ê´€ê³„ ë¶„ì„ì— ë” ì í•©í•  ìˆ˜ ìˆìŒ
                result = self.pathrag.query(query, mode="graph", max_paths=10, k=top_n * 2)
                return self._post_process_result(result)
        
            def analyze_creator_strategy(self, creator_name: str) -> str:
                """í¬ë¦¬ì—ì´í„° ì „ëµ ë¶„ì„"""
                query = f"ì›¹íˆ° ì‘ê°€ '{creator_name}'ì˜ ì‘í’ˆ ìŠ¤íƒ€ì¼, ì£¼ìš” ì£¼ì œ, ì„±ê³µ ì „ëµ ë“±ì„ ë¶„ì„í•´ì¤˜."
                print(f"Executing creator strategy query for: {creator_name}")
                result = self.pathrag.query(query, mode="hybrid", max_paths=8, k=5)
                return self._post_process_result(result)
        
            def recommend_similar_webtoons(self, webtoon_title: str, num_recs: int = 5) -> str:
                """ìœ ì‚¬ ì›¹íˆ° ì¶”ì²œ"""
                # ìƒì„¸ ì •ë³´ í™œìš© ì¿¼ë¦¬
                query = f"ì›¹íˆ° '{webtoon_title}'ê³¼ ì¤„ê±°ë¦¬, ë¶„ìœ„ê¸°, ê·¸ë¦¼ì²´, ì£¼ì œ ë©´ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë‹¤ë¥¸ ì›¹íˆ° {num_recs}ê°œë¥¼ ì¶”ì²œí•´ì£¼ê³ , ê° ì¶”ì²œì˜ ì´ìœ ë¥¼ ì„¤ëª…í•´ì¤˜."
                print(f"Executing similar webtoon query for: {webtoon_title}")
                result = self.pathrag.query(query, mode="hybrid", max_paths=10, k=num_recs * 2)
                # TODO: ê²°ê³¼ì—ì„œ ì›¹íˆ° ëª©ë¡ë§Œ ì¶”ì¶œí•˜ëŠ” í›„ì²˜ë¦¬ í•„ìš” ê°€ëŠ¥ì„±
                return self._post_process_result(result)
        
            def recommend_by_criteria(self, criteria_text: str, num_recs: int = 5) -> str:
                """ì¡°ê±´ ê¸°ë°˜ ì›¹íˆ° ì¶”ì²œ"""
                query = f"ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì›¹íˆ° {num_recs}ê°œë¥¼ ì¶”ì²œí•´ì¤˜: {criteria_text}. ê° ì¶”ì²œ ì´ìœ ë„ ì„¤ëª…í•´ì¤˜."
                print(f"Executing criteria-based recommendation query: {criteria_text}")
                result = self.pathrag.query(query, mode="hybrid", max_paths=10, k=num_recs * 2)
                # TODO: ê²°ê³¼ í›„ì²˜ë¦¬
                return self._post_process_result(result)
        
        ```
        
    2. **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (`tests/test_pathrag_analyzer.py`):**
        - `WebtoonPathRAG` ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì¸ë±ì‹± ì™„ë£Œ ìƒíƒœ ê°€ì •).
        - `PathRAGAnalyzer` ì¸ìŠ¤í„´ìŠ¤ ìƒì„±.
        - ê° ë¶„ì„/ì¶”ì²œ í•¨ìˆ˜ í˜¸ì¶œ ë° ê²°ê³¼ í™•ì¸ (í…ìŠ¤íŠ¸ ì¶œë ¥).
- **ì™„ë£Œ ê¸°ì¤€:**
    - ì£¼ìš” ë¶„ì„/ì¶”ì²œ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¿¼ë¦¬ ì²˜ë¦¬ í•¨ìˆ˜ êµ¬í˜„ ì™„ë£Œ.
    - PathRAG ê²°ê³¼ í›„ì²˜ë¦¬ ë¡œì§ ê¸°ë³¸ êµ¬í˜„.
    - í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¡œ ê° ê¸°ëŠ¥ í˜¸ì¶œ ë° ì‘ë‹µ í™•ì¸.

### **WCAI-PR03: PathRAG ì„±ëŠ¥ ìµœì í™” ë° í‰ê°€** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 60ë¶„)

- **ì„¤ëª…:** PathRAG ì¿¼ë¦¬ ì„±ëŠ¥(ì‘ë‹µ ì†ë„, í’ˆì§ˆ, í† í° ì‚¬ìš©ëŸ‰)ì„ í‰ê°€í•˜ê³  ê°œì„ í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° íŠœë‹ (`QueryParam`):**
        - `recommend_by_criteria` ë“± ì£¼ìš” í•¨ìˆ˜ì— ëŒ€í•´ `mode` ('hybrid', 'graph', 'vector'), `k`, `max_paths`, `max_path_length` ë³€ê²½í•˜ë©° ê²°ê³¼ ë¹„êµ.
        - ì˜ˆ: `mode='graph'`ê°€ ê´€ê³„ ê¸°ë°˜ ì§ˆë¬¸ì— ë” ì¢‹ì€ì§€, `k` ê°’ì„ ëŠ˜ë¦¬ë©´ ì¶”ì²œ ë‹¤ì–‘ì„±ì´ ì¦ê°€í•˜ëŠ”ì§€ í™•ì¸.
    2. **ë°ì´í„° ì¸ë±ì‹± í…ìŠ¤íŠ¸ ìµœì í™”:** (WCAI-PR01 ê´€ë ¨) `_generate_webtoon_text` í•¨ìˆ˜ ê²°ê³¼ë¬¼ì˜ êµ¬ì¡°ë‚˜ ìƒì„¸ ìˆ˜ì¤€ì„ ë³€ê²½í–ˆì„ ë•Œ PathRAG ì‘ë‹µ í’ˆì§ˆ ë³€í™” ê´€ì°°.
    3. **LLM í”„ë¡¬í”„íŠ¸ ê²€í† :** WCAI-PR02ì˜ ì¿¼ë¦¬ ìƒì„± ë¡œì§ ë˜ëŠ” PathRAG ë‚´ë¶€ LLM í”„ë¡¬í”„íŠ¸(ìˆ˜ì • ê°€ëŠ¥í•˜ë‹¤ë©´) ê²€í† .
    4. **í† í° ì‚¬ìš©ëŸ‰ ì¸¡ì •:** LangChain Callback Handler ë“±ì„ ì‚¬ìš©í•˜ì—¬ `WebtoonPathRAG.query` í˜¸ì¶œ ì‹œ LLM í† í° ì‚¬ìš©ëŸ‰ ì¸¡ì • ë° ê¸°ë¡. íŒŒë¼ë¯¸í„° ë³€ê²½ì— ë”°ë¥¸ ë³€í™” í™•ì¸.
    5. ê°„ë‹¨í•œ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ ìš”ì•½ (`docs/pathrag_performance.md`).
- **ì™„ë£Œ ê¸°ì¤€:**
    - ì£¼ìš” ì¿¼ë¦¬ì— ëŒ€í•œ PathRAG íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œë„ ë° ê²°ê³¼ ê¸°ë¡.
    - í† í° ì‚¬ìš©ëŸ‰ ì¸¡ì • ë°©ë²• í™•ì¸ ë° ì¼ë¶€ ì¿¼ë¦¬ì— ëŒ€í•´ ì¸¡ì •.
    - ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ ê°„ëµíˆ ë¬¸ì„œí™”.

## **Phase 4: UI í†µí•© ë° ìµœì¢…í™” (ë‹¤ì¤‘ ì—í”¼ì†Œë“œ + PathRAG)**

### **WCAI-P10: Streamlit UI - ì…ë ¥ ë°©ì‹ ìˆ˜ì • (ë‹¤ì¤‘ ì´ë¯¸ì§€/ì‹œí€€ìŠ¤ ì„ íƒ)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 60ë¶„)

- **ì„¤ëª…:** ì‚¬ìš©ìê°€ ì—¬ëŸ¬ ê°œì˜ ì—í”¼ì†Œë“œ ì´ë¯¸ì§€ íŒŒì¼ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•˜ê±°ë‚˜, ìƒ˜í”Œ ì›¹íˆ°ì˜ ë¶„ì„ ëŒ€ìƒ ì‹œí€€ìŠ¤ë¥¼ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ UIë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **`app.py` ì‚¬ì´ë“œë°” UI êµ¬í˜„:**
        
        ```python
        import streamlit as st
        from src.utils.data_loader import WebtoonDataLoader
        # ... other imports ...
        
        st.set_page_config(page_title="Webtoon Analysis + PathRAG", layout="wide")
        st.sidebar.title("ì›¹íˆ° ë¶„ì„ & ì¶”ì²œ Agent")
        st.sidebar.markdown("---")
        
        # --- ì…ë ¥ ì„ íƒ ---
        input_method = st.sidebar.radio("ë¶„ì„ ëŒ€ìƒ ì„ íƒ", ["ìƒ˜í”Œ ì›¹íˆ° ì‚¬ìš©", "ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ"], index=0)
        
        uploaded_files = None
        selected_webtoon_id = None
        selected_episode_ids = None
        selected_episode_titles = None
        
        try:
            loader = WebtoonDataLoader()
            webtoon_ids = loader.get_all_webtoon_ids()
        except Exception as e:
             st.sidebar.error(f"ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
             webtoon_ids = []
        
        if input_method == "ìƒ˜í”Œ ì›¹íˆ° ì‚¬ìš©":
            if not webtoon_ids:
                st.sidebar.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ìƒ˜í”Œ ì›¹íˆ°ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                selected_webtoon_id_from_sample = st.sidebar.selectbox(
                    "ë¶„ì„í•  ì›¹íˆ° ì„ íƒ", webtoon_ids, format_func=lambda x: loader.get_webtoon_metadata(x).get('title', x)
                )
                if selected_webtoon_id_from_sample:
                     sequence_info = loader.get_episode_sequence_info(selected_webtoon_id_from_sample)
                     if sequence_info and sequence_info[0]:
                         selected_webtoon_id = selected_webtoon_id_from_sample
                         selected_episode_ids = sequence_info[0] # ì •ì˜ëœ ì‹œí€€ìŠ¤ ì‚¬ìš©
                         selected_episode_titles = sequence_info[1]
                         st.sidebar.caption(f"ì„ íƒë¨: {loader.get_webtoon_metadata(selected_webtoon_id)['title']} ({len(selected_episode_ids)} ì—í”¼ì†Œë“œ)")
                     else:
                         st.sidebar.warning(f"{selected_webtoon_id_from_sample}ì˜ ì—í”¼ì†Œë“œ ì‹œí€€ìŠ¤ ì •ë³´ ì—†ìŒ.")
        
        elif input_method == "ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ":
            uploaded_files = st.sidebar.file_uploader(
                "ì—°ì†ëœ ì—í”¼ì†Œë“œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”.",
                type=["jpg", "jpeg", "png"],
                accept_multiple_files=True
            )
            if uploaded_files:
                st.sidebar.caption(f"{len(uploaded_files)}ê°œ ì´ë¯¸ì§€ ì—…ë¡œë“œë¨.")
                # ì—…ë¡œë“œ ì‹œ ID/Title ì„ì˜ ì§€ì •
                selected_webtoon_id = "uploaded_webtoon"
                selected_episode_ids = [f"ep{i+1}" for i in range(len(uploaded_files))]
                selected_episode_titles = [f"Uploaded Episode {i+1}" for i in range(len(uploaded_files))]
        
        # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼ (ìƒíƒœì— ë”°ë¼ í™œì„±í™”)
        can_analyze = (selected_webtoon_id and selected_episode_ids) or (uploaded_files)
        analyze_button_placeholder = st.sidebar.empty()
        
        # --- ë©”ì¸ ì˜ì—­ (ë‹¤ìŒ í‹°ì¼“ì—ì„œ ì±„ì›€) ---
        st.title("âœ¨ Webtoon Sequence Analysis + PathRAG")
        st.markdown("---")
        main_area = st.container()
        # ...
        
        # ë²„íŠ¼ ìƒì„±
        if analyze_button_placeholder.button("ì›¹íˆ° ì‹œí€€ìŠ¤ ë¶„ì„ ì‹¤í–‰", type="primary", key="analyze_sequence_btn", disabled=not can_analyze):
            # TODO: WCAI-P12ì—ì„œ ë¡œì§ ì—°ê²°
            with main_area: st.info("ë¶„ì„ ì‹¤í–‰ ë¡œì§ ì—°ê²° ì˜ˆì •...")
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:** ë‹¤ì¤‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ìƒ˜í”Œ ì‹œí€€ìŠ¤ ì„ íƒ UI êµ¬í˜„ ì™„ë£Œ. ì…ë ¥ ìƒíƒœ ê´€ë¦¬ ë° ë²„íŠ¼ í™œì„±í™” ë¡œì§ êµ¬í˜„.

### **WCAI-P11: Streamlit UI - ê²°ê³¼ í‘œì‹œ ìˆ˜ì • (ì‹œí€€ìŠ¤ + PathRAG)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 90ë¶„)

- **ì„¤ëª…:** WCAI Agentì˜ ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ì™€ PathRAGì˜ ë¶„ì„/ì¶”ì²œ ê²°ê³¼ë¥¼ í†µí•©ì ìœ¼ë¡œ ë³´ì—¬ì£¼ë„ë¡ UIë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜ êµ¬í˜„ (`app.py` ë˜ëŠ” `src/app/ui_display.py`):**
        
        ```python
        import streamlit as st
        from typing import Dict, List, Any
        
        def display_sequence_analysis(results_data: Dict):
            """WCAI Agent ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
            st.subheader(f"ì›¹íˆ° ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼: {results_data.get('episode_title', results_data.get('webtoon_id', 'N/A'))}")
            if results_data.get("error"):
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {results_data['error']}")
                return
        
            st.markdown("**ğŸ“œ ì‹œí€€ìŠ¤ ì „ì²´ ìš”ì•½**")
            st.markdown(results_data.get('sequence_summary', 'ìš”ì•½ ì—†ìŒ'))
            st.markdown("---")
        
            with st.expander("ğŸ“š ì—í”¼ì†Œë“œë³„ ìƒì„¸ ë¶„ì„ ë³´ê¸°", expanded=False):
                texts = results_data.get('per_episode_extracted_text', [])
                analyses = results_data.get('per_episode_visual_analysis', [])
                titles = results_data.get('episode_titles', [''] * len(texts))
        
                if texts or analyses:
                     for i in range(max(len(texts), len(analyses))):
                         st.markdown(f"**Episode {i+1}: {titles[i] if i < len(titles) else ''}**")
                         cols = st.columns(2)
                         with cols[0]:
                             st.caption("ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                             st.text_area(f"txt_{i}", texts[i] if i < len(texts) else "N/A", height=200, key=f"text_ep_{i}")
                         with cols[1]:
                             st.caption("ğŸ–¼ï¸ ì‹œê°ì  ë¶„ì„")
                             st.text_area(f"vis_{i}", analyses[i] if i < len(analyses) else "N/A", height=200, key=f"analysis_ep_{i}")
                         st.markdown("---")
                else:
                     st.info("ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        def display_pathrag_results(query: str, result_text: str):
             """PathRAG ì¿¼ë¦¬ ê²°ê³¼ í‘œì‹œ"""
             st.subheader("ğŸ’¬ PathRAG ë¶„ì„/ì¶”ì²œ ê²°ê³¼")
             st.markdown(f"**ì§ˆë¬¸:** {query}")
             st.markdown("**ë‹µë³€:**")
             st.markdown(result_text) # ê²°ê³¼ í…ìŠ¤íŠ¸ í‘œì‹œ
             st.markdown("---")
        
        def display_graph_visualization(html_file: str = "data/graph_exports/webtoon_graph_visualization.html"):
            """ê·¸ë˜í”„ ì‹œê°í™” HTML í‘œì‹œ"""
            st.subheader("ğŸ•¸ï¸ ì›¹íˆ° ì§€ì‹ ê·¸ë˜í”„ ì‹œê°í™”")
            if os.path.exists(html_file):
                 try:
                     with open(html_file, 'r', encoding='utf-8') as f:
                         html_content = f.read()
                     st.components.v1.html(html_content, height=600, scrolling=True)
                 except Exception as e:
                     st.error(f"ê·¸ë˜í”„ ì‹œê°í™” íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            else:
                 st.warning("ê·¸ë˜í”„ ì‹œê°í™” íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ êµ¬ì¶• íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        ```
        
    2. **ë©”ì¸ ì˜ì—­ ë ˆì´ì•„ì›ƒ êµ¬ì„± (`app.py`):** íƒ­ ë˜ëŠ” ì„¹ì…˜ìœ¼ë¡œ ê²°ê³¼ êµ¬ë¶„.
        
        ```python
        # ... (ì‚¬ì´ë“œë°” ì½”ë“œ ì´í›„) ...
        # ë©”ì¸ ì˜ì—­
        st.title("âœ¨ Webtoon Sequence Analysis + PathRAG")
        st.markdown("---")
        
        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì˜ì—­ (Session State í™œìš© ê¶Œì¥)
        if 'analysis_result' not in st.session_state: st.session_state['analysis_result'] = None
        if 'pathrag_query' not in st.session_state: st.session_state['pathrag_query'] = ""
        if 'pathrag_result' not in st.session_state: st.session_state['pathrag_result'] = None
        
        # --- ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼ í‘œì‹œ ---
        if st.session_state['analysis_result']:
            display_sequence_analysis(st.session_state['analysis_result'])
        
        st.markdown("---")
        
        # --- PathRAG ë¶„ì„/ì¶”ì²œ ---
        st.subheader("ğŸ” PathRAG ê¸°ë°˜ ë¶„ì„ ë° ì¶”ì²œ")
        pathrag_query_input = st.text_area("ì§ˆë¬¸ ì…ë ¥:", height=100, key="pathrag_query_input", placeholder="ì˜ˆ: 'ë¡œë§¨ìŠ¤ ì—†ê³  ì•¡ì…˜ ìŠ¤ë¦´ëŸ¬ ì›¹íˆ° ì¶”ì²œí•´ì¤˜', 'ì¸ê¸° íŒíƒ€ì§€ ì›¹íˆ°ë“¤ì˜ ê³µí†µì ì€?'")
        pathrag_query_button = st.button("PathRAGì—ê²Œ ì§ˆë¬¸í•˜ê¸°", key="pathrag_query_btn")
        
        if pathrag_query_button and pathrag_query_input:
            # TODO: WCAI-P12ì—ì„œ PathRAG ì¿¼ë¦¬ ë¡œì§ í˜¸ì¶œ
            st.session_state['pathrag_query'] = pathrag_query_input
            st.info("PathRAG ì¿¼ë¦¬ ì‹¤í–‰ ë¡œì§ ì—°ê²° ì˜ˆì •...")
            # ì„ì‹œ ê²°ê³¼ í‘œì‹œ
            st.session_state['pathrag_result'] = "PathRAGë¡œë¶€í„° ë‹µë³€ì„ ë°›ì•„ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì—°ê²° ì˜ˆì •)"
        
        if st.session_state['pathrag_result']:
             display_pathrag_results(st.session_state['pathrag_query'], st.session_state['pathrag_result'])
        
        st.markdown("---")
        
        # --- ê·¸ë˜í”„ ì‹œê°í™” ---
        # TODO: WCAI-P12ì—ì„œ ì—°ë™
        display_graph_visualization()
        
        # ì´ˆê¸° ì•ˆë‚´ ë©”ì‹œì§€ (ê²°ê³¼ ì—†ì„ ë•Œ)
        if not st.session_state['analysis_result'] and not st.session_state['pathrag_result']:
             st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ìƒ˜í”Œì„ ì„ íƒ í›„ 'ë¶„ì„ ì‹¤í–‰', ë˜ëŠ” ì•„ë˜ì— PathRAG ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:**
    - ì‹œí€€ìŠ¤ ë¶„ì„ ê²°ê³¼(ìš”ì•½+ìƒì„¸) í‘œì‹œ í•¨ìˆ˜ ë° UI êµ¬í˜„ ì™„ë£Œ.
    - PathRAG ì¿¼ë¦¬ ì…ë ¥ ë° ê²°ê³¼ í‘œì‹œ UI êµ¬í˜„ ì™„ë£Œ.
    - ê·¸ë˜í”„ ì‹œê°í™” í‘œì‹œ UI êµ¬í˜„ ì™„ë£Œ.

### **WCAI-P12: Streamlit - Agent/PathRAG ì—°ë™ (ìµœì¢…)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 75ë¶„)

- **ì„¤ëª…:** UI ì…ë ¥ê³¼ ë°±ì—”ë“œ ë¡œì§(ì‹œí€€ìŠ¤ ë¶„ì„ Agent, PathRAG ì¿¼ë¦¬ í•¨ìˆ˜)ì„ ìµœì¢… ì—°ë™í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **í•„ìš” ëª¨ë“ˆ import (`app.py`):**
        
        ```python
        from src.agents.webtoon_agent import analyze_webtoon_sequence
        from src.analysis.pathrag_analyzer import PathRAGAnalyzer # PathRAG ë¶„ì„ê¸°
        from src.graph.pathrag_integration import WebtoonPathRAG # PathRAG ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ìš©
        from PIL import Image
        import os
        
        ```
        
    2. **ë°±ì—”ë“œ ê°ì²´ ì´ˆê¸°í™” (ìºì‹± í™œìš©):** `@st.cache_resource`ë¥¼ ì‚¬ìš©í•˜ì—¬ PathRAG ì¸ìŠ¤í„´ìŠ¤ ë“± ë¬´ê±°ìš´ ê°ì²´ ë¡œë“œ.
        
        ```python
        # app.py ìƒë‹¨ ë˜ëŠ” ë³„ë„ ëª¨ë“ˆ
        @st.cache_resource
        def get_pathrag_analyzer():
            print("Initializing WebtoonPathRAG and PathRAGAnalyzer...")
            # API í‚¤ ë¡œë“œ í™•ì¸
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                st.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                st.stop()
            try:
                # PathRAG ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì¸ë±ìŠ¤ ë¹Œë“œëŠ” ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ë¡œ ìˆ˜í–‰ ê°€ì •)
                # ì‹¤ì œë¡œëŠ” ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë¡œì§ í•„ìš”
                pathrag_instance = WebtoonPathRAG(api_key=api_key)
                analyzer = PathRAGAnalyzer(pathrag_instance)
                print("PathRAGAnalyzer initialized.")
                return analyzer
            except Exception as e:
                 st.error(f"PathRAG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                 st.stop()
        
        analyzer = get_pathrag_analyzer()
        
        ```
        
    3. **'ì›¹íˆ° ì‹œí€€ìŠ¤ ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ ë¡œì§ êµ¬í˜„ (`app.py`):**
        
        ```python
        # ë²„íŠ¼ ë¡œì§ ìˆ˜ì •
        if analyze_button_placeholder.button("ì›¹íˆ° ì‹œí€€ìŠ¤ ë¶„ì„ ì‹¤í–‰", type="primary", key="analyze_sequence_btn", disabled=not can_analyze):
            with main_area:
                st.empty() # ì´ì „ ë‚´ìš© ì§€ìš°ê¸°
                st.session_state['analysis_result'] = None # ê²°ê³¼ ì´ˆê¸°í™”
                st.session_state['pathrag_result'] = None # ë‹¤ë¥¸ ê²°ê³¼ë„ ì´ˆê¸°í™”
        
                images_to_analyze = []
                analyze_webtoon_id = "custom_upload"
                analyze_episode_ids = []
                analyze_episode_titles = []
        
                # ì…ë ¥ ì†ŒìŠ¤ ê²°ì •
                if uploaded_files:
                    try:
                        images_to_analyze = [Image.open(img) for img in uploaded_files]
                        # RGBA -> RGB ë³€í™˜ ì¶”ê°€
                        images_to_analyze = [img.convert('RGB') if img.mode == 'RGBA' else img for img in images_to_analyze]
                        analyze_episode_ids = [f"ep{i+1}" for i in range(len(uploaded_files))]
                        analyze_episode_titles = [f"Uploaded Ep {i+1}" for i in range(len(uploaded_files))]
                        print(f"Processing {len(images_to_analyze)} uploaded images.")
                    except Exception as e:
                        st.error(f"ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        st.stop()
                elif use_sample and selected_webtoon_id and selected_episode_ids:
                    try:
                        images_to_analyze = loader.load_episode_sequence_images(selected_webtoon_id, selected_episode_ids)
                        analyze_webtoon_id = selected_webtoon_id
                        analyze_episode_ids = selected_episode_ids # ì´ë¯¸ ë¡œë“œë¨
                        analyze_episode_titles = selected_episode_titles # ì´ë¯¸ ë¡œë“œë¨
                        print(f"Processing sample sequence: {analyze_webtoon_id} - {analyze_episode_ids}")
                    except Exception as e:
                        st.error(f"ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
                        st.stop()
        
                # ë¶„ì„ ì‹¤í–‰
                if images_to_analyze:
                    with st.spinner('ì›¹íˆ° ì‹œí€€ìŠ¤ ë¶„ì„ ì¤‘... (OCR, ë¶„ì„, ìš”ì•½)'):
                        try:
                            # ì—ì´ì „íŠ¸ í•¨ìˆ˜ í˜¸ì¶œ (ë°ì´í„° ì¶”ê°€ ì „ë‹¬)
                            analysis_result_data = analyze_webtoon_sequence(
                                webtoon_id=analyze_webtoon_id,
                                episode_ids=analyze_episode_ids
                                # analyze_webtoon_sequence í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ë¯¸ì§€ ë¡œë”©í•˜ë„ë¡ ìˆ˜ì •í•˜ê±°ë‚˜,
                                # ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì „ë‹¬ë°›ë„ë¡ ìˆ˜ì • í•„ìš”. ì—¬ê¸°ì„  ì§ì ‘ ì „ë‹¬ ê°€ì •.
                                # ë§Œì•½ analyze_webtoon_sequenceê°€ IDë¡œ ë¡œë”©í•œë‹¤ë©´ images ì „ë‹¬ ë¶ˆí•„ìš”.
                                # ì•„ë˜ ì½”ë“œëŠ” í•¨ìˆ˜ê°€ IDë¡œ ë¡œë”©í•œë‹¤ê³  ê°€ì •.
                            )
                            # ê²°ê³¼ë¥¼ Session Stateì— ì €ì¥
                            st.session_state['analysis_result'] = analysis_result_data
                            print("Sequence analysis complete.")
                            # ê²°ê³¼ í‘œì‹œë¥¼ ìœ„í•´ ë¦¬ë¡œë“œ (Streamlit ì‘ë™ ë°©ì‹)
                            st.rerun()
        
                        except Exception as e:
                            st.error(f"ì›¹íˆ° ì‹œí€€ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                else:
                    st.warning("ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # --- Session Stateì— ê²°ê³¼ ìˆìœ¼ë©´ í‘œì‹œ ---
        if st.session_state['analysis_result']:
             display_sequence_analysis(st.session_state['analysis_result'])
        # ... (PathRAG ë° ê·¸ë˜í”„ í‘œì‹œ ë¡œì§) ...
        
        ```
        
    4. **'PathRAGì—ê²Œ ì§ˆë¬¸í•˜ê¸°' ë²„íŠ¼ ë¡œì§ êµ¬í˜„ (`app.py`):**
        
        ```python
        # PathRAG ì¿¼ë¦¬ ë²„íŠ¼ ë¡œì§
        if pathrag_query_button and pathrag_query_input:
            st.session_state['pathrag_query'] = pathrag_query_input
            st.session_state['pathrag_result'] = None # ê²°ê³¼ ì´ˆê¸°í™”
            st.session_state['analysis_result'] = None # ë‹¤ë¥¸ ê²°ê³¼ ì´ˆê¸°í™”
        
            with st.spinner("PathRAG ë¶„ì„/ì¶”ì²œ ì§„í–‰ ì¤‘..."):
                try:
                    # TODO: ì¿¼ë¦¬ ìœ í˜•(ë¶„ì„, ì¶”ì²œ ë“±)ì— ë”°ë¼ analyzerì˜ ë‹¤ë¥¸ í•¨ìˆ˜ í˜¸ì¶œ
                    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì¼ë°˜ ì¿¼ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ ì˜ˆì‹œ
                    # ì‹¤ì œë¡œëŠ” selectbox ë“±ìœ¼ë¡œ ìœ í˜• ì„ íƒ í›„ ë¶„ê¸° ì²˜ë¦¬ í•„ìš”
                    if "ì¶”ì²œ" in pathrag_query_input:
                        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ ì˜ˆì‹œ (ê°œì„  í•„ìš”)
                         result_text = analyzer.recommend_by_criteria(criteria_text=pathrag_query_input)
                    elif "ë¶„ì„" in pathrag_query_input or "íŠ¹ì§•" in pathrag_query_input:
                         # íŒ¨í„´ ë¶„ì„ í•¨ìˆ˜ í˜¸ì¶œ (ì˜ˆì‹œ)
                         result_text = analyzer.find_popular_pattern(genre=None) # ì¿¼ë¦¬ì—ì„œ ì¥ë¥´ ì¶”ì¶œ í•„ìš”
                    else: # ì¼ë°˜ ì¿¼ë¦¬
                         result_text = analyzer.pathrag.query(pathrag_query_input) # ê¸°ë³¸ query ì§ì ‘ í˜¸ì¶œ
                         result_text = analyzer._post_process_result(result_text) # í›„ì²˜ë¦¬
        
                    st.session_state['pathrag_result'] = result_text
                    print("PathRAG query complete.")
                    st.rerun()
        
                except Exception as e:
                    st.error(f"PathRAG ì¿¼ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.session_state['pathrag_result'] = f"ì˜¤ë¥˜ ë°œìƒ: {e}" # ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
        # --- PathRAG ê²°ê³¼ í‘œì‹œ ---
        if st.session_state['pathrag_result']:
             display_pathrag_results(st.session_state['pathrag_query'], st.session_state['pathrag_result'])
        
        ```
        
    5. **ê·¸ë˜í”„ ì‹œê°í™” ì—°ë™:** `display_graph_visualization()` í•¨ìˆ˜ í˜¸ì¶œ ë¶€ë¶„ì„ í™œì„±í™”. í•´ë‹¹ HTML íŒŒì¼ì´ ìƒì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.
- **ì™„ë£Œ ê¸°ì¤€:**
    - UI ì…ë ¥ -> ë°±ì—”ë“œ ë¡œì§(Agent/PathRAG) í˜¸ì¶œ -> ê²°ê³¼ í‘œì‹œ ì „ì²´ íë¦„ ì—°ë™ ì™„ë£Œ.
    - Streamlit Session Stateë¥¼ í™œìš©í•œ ê²°ê³¼ ìœ ì§€ ë° í‘œì‹œ.
    - ë°±ì—”ë“œ í˜¸ì¶œ ì‹œ ë¡œë”© ìŠ¤í”¼ë„ˆ í‘œì‹œ ë° ì˜¤ë¥˜ ì²˜ë¦¬ êµ¬í˜„.

### **WCAI-P13: End-to-End í†µí•© í…ŒìŠ¤íŠ¸ (ë‹¤ì¤‘ ì—í”¼ì†Œë“œ + PathRAG)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 90ë¶„)

- **ì„¤ëª…:** ì „ì²´ ì‹œìŠ¤í…œì˜ í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³  ë””ë²„ê¹…í•©ë‹ˆë‹¤. (ì‹œí€€ìŠ¤ ë¶„ì„ ë° PathRAG ê¸°ëŠ¥ í¬í•¨)
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„¸í™” (`tests/test_scenarios.md`):**
        - ìƒ˜í”Œ ì‹œí€€ìŠ¤ ì„ íƒ -> ë¶„ì„ ì‹¤í–‰ -> ì‹œí€€ìŠ¤ ìš”ì•½, ì—í”¼ì†Œë“œë³„ OCR/ë¶„ì„ ê²°ê³¼ í™•ì¸.
        - ë‹¤ì¤‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ -> ë¶„ì„ ì‹¤í–‰ -> ê²°ê³¼ í™•ì¸.
        - PathRAG ì¿¼ë¦¬ ì…ë ¥ (ìœ ì‚¬ ì›¹íˆ°, íŠ¹ì • ì¡°ê±´ ì¶”ì²œ, íŒ¨í„´ ë¶„ì„ ë“±) -> ë°˜í™˜ëœ í…ìŠ¤íŠ¸ ê²°ê³¼ì˜ ê´€ë ¨ì„±, ë…¼ë¦¬ì„± í™•ì¸.
        - ê·¸ë˜í”„ ì‹œê°í™” íƒ­/ì„¹ì…˜ í™•ì¸.
        - ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸ (ì´ë¯¸ì§€ 0ê°œ/1ê°œ ì—…ë¡œë“œ, ë¹ˆ ì¿¼ë¦¬ ì…ë ¥ ë“±).
        - ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ (ì˜ëª»ëœ API í‚¤, ë¶„ì„ ì¤‘ íƒ€ì„ì•„ì›ƒ ë“±).
    2. **ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰:** Streamlit ì•± ì§ì ‘ ì‚¬ìš©í•˜ë©° í…ŒìŠ¤íŠ¸. ë¸Œë¼ìš°ì € ê°œë°œì ë„êµ¬ ì½˜ì†” ë° ì„œë²„ ë¡œê·¸ í™•ì¸.
    3. **ë²„ê·¸ ì‹ë³„ ë° ìˆ˜ì •:** ë°ì´í„° íë¦„, ìƒíƒœ ê´€ë¦¬(Session State), API í˜¸ì¶œ ì˜¤ë¥˜, UI í‘œì‹œ ì˜¤ë¥˜, PathRAG ì¿¼ë¦¬/ì‘ë‹µ ë¬¸ì œ ë“± ì „ ì˜ì—­ ë””ë²„ê¹…. íŠ¹íˆ ê¸´ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œê°„ ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê´€ì°°.
    4. **ê²°ê³¼ ê¸°ë¡ (`tests/test_results.md`):** ê° ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„±ê³µ/ì‹¤íŒ¨, ë°œê²¬ëœ ì´ìŠˆ, í•´ê²° ë‚´ìš©, ì„±ëŠ¥(ì‘ë‹µ ì‹œê°„) ë“± ê¸°ë¡.
- **ì™„ë£Œ ê¸°ì¤€:** ì •ì˜ëœ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì™„ë£Œ. ì‹ë³„ëœ ì£¼ìš” ë²„ê·¸ ìˆ˜ì • ì™„ë£Œ. ì‹œìŠ¤í…œ ì•ˆì •ì„± í™•ë³´.

### **WCAI-P14: ìµœì¢… README ë° ë°ëª¨ ì¤€ë¹„ (ë‹¤ì¤‘ ì—í”¼ì†Œë“œ + PathRAG)** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 60ë¶„)

- **ì„¤ëª…:** ìµœì¢… ê¸°ëŠ¥ì„ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ ë¬¸ì„œë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ë°ëª¨ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. [**README.md](http://readme.md/) ìµœì¢… ì™„ì„±:**
        - í”„ë¡œì íŠ¸ ëª©í‘œ, ìµœì¢… êµ¬í˜„ ê¸°ëŠ¥ (ì‹œí€€ìŠ¤ ë¶„ì„, PathRAG ê¸°ë°˜ ë¶„ì„/ì¶”ì²œ ìƒì„¸ ì„¤ëª…) ëª…í™•í™”.
        - ì„¤ì¹˜ (PathRAG í¬í•¨), API í‚¤ ì„¤ì •, **ë°ì´í„° ì¤€ë¹„ ê°€ì´ë“œ** (ìƒ˜í”Œ êµ¬ì¡°, ì´ë¯¸ì§€ í˜•ì‹/ìº¡ì²˜ ê°€ì´ë“œ), **ê·¸ë˜í”„/ì¸ë±ìŠ¤ ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë°©ë²•** ëª…ì‹œ.
        - **UI ì‚¬ìš©ë²• ìµœì¢… ì•ˆë‚´** (ì‹œí€€ìŠ¤ ë¶„ì„ ì‹¤í–‰, PathRAG ì¿¼ë¦¬ ë°©ë²• ë“± ìŠ¤í¬ë¦°ìƒ· í¬í•¨).
        - í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜(ë°ì´í„° íë¦„ë„ í¬í•¨) ìµœì¢…ë³¸ ìš”ì•½.
        - **ê²°ê³¼ ì˜ˆì‹œ:** ì‹¤ì œ ë¶„ì„ ê²°ê³¼ ìŠ¤í¬ë¦°ìƒ· (ì‹œí€€ìŠ¤ ìš”ì•½, PathRAG ì¶”ì²œ/ë¶„ì„ ë‹µë³€ ì˜ˆì‹œ).
        - **ì œí•œ ì‚¬í•­:** OCR ì •í™•ë„ í•œê³„, PathRAG ì¿¼ë¦¬ ì´í•´ë„, ë¶„ì„/ì¿¼ë¦¬ ì‹œê°„, ë¹„ìš© ë¬¸ì œ, ìƒ˜í”Œ ë°ì´í„° ê·œëª¨ í•œê³„ ë“± ì†”ì§í•˜ê²Œ ëª…ì‹œ.
        - í–¥í›„ ê°œì„  ë°©í–¥ êµ¬ì²´í™” (URL ì…ë ¥ ì§€ì›, ëª¨ë¸ íŒŒì¸íŠœë‹, ê·¸ë˜í”„ ê´€ê³„ ê°•í™” ë“±).
        - ë¼ì´ì„ ìŠ¤ ëª…ì‹œ.
    2. **ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ ìµœì¢… í™•ì •:** ì§§ì€ ì‹œê°„ ë‚´ì— í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ê°€ì¹˜(ì‹œí€€ìŠ¤ ë¶„ì„ ëŠ¥ë ¥, PathRAGë¥¼ í†µí•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ)ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ êµ¬ì„±.
    3. **ë°ëª¨ìš© ìŠ¤í¬ë¦°ìƒ·/GIF ìµœì¢… ì¤€ë¹„:** ì™„ì„±ëœ UI ë° ì¸ìƒì ì¸ ê²°ê³¼ í™”ë©´ ìë£Œ ì¤€ë¹„.
- **ì™„ë£Œ ê¸°ì¤€:** ëª¨ë“  ê¸°ëŠ¥ê³¼ ì‚¬ìš©ë²•ì´ ìƒì„¸íˆ ê¸°ìˆ ëœ ìµœì¢… README ì™„ì„±. ë°ëª¨ ì‹œì—° ìë£Œ ì¤€ë¹„ ì™„ë£Œ.

### **WCAI-P15: ìµœì¢… ì½”ë“œ ì •ë¦¬ ë° ì œì¶œ ì¤€ë¹„** (ì˜ˆìƒ ì†Œìš”ì‹œê°„: 30ë¶„)

- **ì„¤ëª…:** ì½”ë“œì˜ ê°€ë…ì„±ì„ ë†’ì´ê³  ìµœì¢… ë²„ì „ì„ GitHubì— í‘¸ì‹œí•˜ì—¬ ì œì¶œ ì¤€ë¹„ë¥¼ ì™„ë£Œí•©ë‹ˆë‹¤.
- **ìˆ˜í–‰ ë‹¨ê³„:**
    1. **ì½”ë“œ ì£¼ì„ ì¶”ê°€/ê²€í† :** ëª¨ë“  ì£¼ìš” í•¨ìˆ˜, í´ë˜ìŠ¤, ë³µì¡í•œ ë¡œì§ì— docstring ë° ì„¤ëª… ì£¼ì„ ì¶”ê°€/ìµœì¢… ê²€í† .
    2. **ì½”ë“œ í¬ë§·íŒ…:** Black, Flake8 ë“± ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ìŠ¤íƒ€ì¼ ì¼ê´€ì„± ìœ ì§€.
    3. **ìµœì¢… ë¦¬ë·°:** ë¶ˆí•„ìš”í•œ ì½”ë“œ, printë¬¸, ì„ì‹œ íŒŒì¼, í•˜ë“œì½”ë”©ëœ ê°’ ë“± ì œê±° ë° ì •ë¦¬. ì„¤ì •ê°’ ë¶„ë¦¬ í™•ì¸ (config ë“±).
    4. **ìµœì¢… í…ŒìŠ¤íŠ¸:** ë§ˆì§€ë§‰ìœ¼ë¡œ ì „ì²´ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ READMEì˜ ì§€ì¹¨ëŒ€ë¡œ ì˜¤ë¥˜ ì—†ì´ ì‹¤í–‰ë˜ëŠ”ì§€ ìµœì¢… í™•ì¸.
    5. **ìµœì¢… ì»¤ë°‹ ë° í‘¸ì‹œ:** ëª¨ë“  ë³€ê²½ì‚¬í•­ì„ GitHub ì €ì¥ì†Œì— ì»¤ë°‹í•˜ê³  í‘¸ì‹œ. ë²„ì „ íƒœê·¸(e.g., `v1.0-final-poc`) ìƒì„± ê³ ë ¤.
        
        ```bash
        git status # ë³€ê²½ì‚¬í•­ í™•ì¸
        git add .
        git commit -m "Finalize project: Complete sequence analysis, PathRAG integration, UI, and documentation"
        git tag v1.0-final-poc # ë²„ì „ íƒœê·¸ ìƒì„±
        git push origin main --tags # main ë¸Œëœì¹˜ì™€ íƒœê·¸ í‘¸ì‹œ
        
        ```
        
- **ì™„ë£Œ ê¸°ì¤€:**
    - ì½”ë“œ ì •ë¦¬ ë° ì£¼ì„ ì™„ë£Œ.
    - ìµœì¢… ë²„ì „ GitHub í‘¸ì‹œ ì™„ë£Œ.
    - í¬íŠ¸í´ë¦¬ì˜¤ë¡œ ì œì¶œ ê°€ëŠ¥í•œ ìƒíƒœ.

---